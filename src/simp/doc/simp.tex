\documentclass[a4]{article}
\bibliographystyle{plain}

\title{A Simplifier/Programmable Grinder for hol98}
\author{Donald Syme\thanks{Myra VanInwegen provided additional
material. Konrad Slind updated this note for {\tt hol98}.}}

% ask Don how to fix the code so that people don't have to say
% ``infix ++''

\include{commands}

\begin{document}
\maketitle
% \tableofcontents

This chapter describes `simplification', which is a powerful new proof
technique available in the latest version of \HOL.

First a word of warning! As always, {\em the more you know about what an
  automated tool can do for you, the more effective it will be for
  you}. Users should ensure they have a good understanding of what
  simplification is before they make large sale use of it in their
  proofs.  This will help avoid the plethora of problems that develop
  from the misapplication of automated tools.

In particular, users new to theorem proving systems should probably
use simplification sparingly, until they have a thorough understanding
of the basics of how a theorem proving system works.

This simplifier is capable of doing a lot.  However this also means it
is difficult to know exactly what it is doing, or why it stops
working.  Because of this, extensive tracing is possible.

This simplifier is based loosely on the Isabelle simplifier.  The
original motivation for doing this work was that I was inspired by
reading the Isabelle reference manual (chapter 10) and wanted to see
how easy such a simplifier would be to implement in \HOL.

\section{What is Simplification?}

In its basic form, simplification is a more general kind of
rewriting. Like rewriting, simplification starts with some term, say
$t_1$, and repeatedly applies a collection of {\it reduction rules} to
the term and its subterms until no more reductions apply.  This produces
the theorem \ml{|- $t_1$ = $t_2$}, which can be utilised in various
ways.

Simplification is only concerned with the case where the reduction rules
prove that the term $t_1$ is {\it equal} to another term $t_2$.  Thus
the domain of operation of simplification is most of what is encompassed
by {\it equational reasoning}.  Simplification can be generalised to
reduction under preorders, but for the moment we need only be concerned
with the equality case.

The simplification library is brought into an interactive session by
invoking
\begin{verbatim}
    load "simpLib";
    open simpLib;
\end{verbatim}

\section{Simpsets}

The simplifier needs data to work with.  This is specified in
{\em simpsets}. Simpsets are an extremely useful way to organise
your work and group theorems together.  You should make it your
aim to develop good simpsets as part of your theories.
A simpset contains:
\begin{itemize}
    \item A set of rewrite theorems, some of which may be conditional.
    \item A set of congruence theorems which specify
          contextual rewriting information.
    \item A set of conversions which get applied to relevant terms.
    \item A "rewrite maker" function.
\end{itemize}
Simpsets are created in two steps:
\begin{enumerate}
   \item Fragments of simpsets (usually one per theory) are created
using the functions {\tt SIMPSET} or the shortcut {\tt rewrites}.
   \item The fragments are composed (merged) using {\tt mk\_simpset} to
make a simpset, or added to an existing simpset using {\tt ++}.
\end{enumerate}
This two stage approach makes the implementation of the simplifier far
cleaner.  However, it can be annoying to make large simpsets by
composing smaller fragments when you only want to add a few theorems.
Hence you can use the infix\footnote{At least it is intended that
\ml{++} be infix. Currently it isn't when you start up HOL, so you
must type \ml{infix ++} to make it so. This is a directive that perhaps
ought to be in your {\tt hol-init.sml} file.} operator \ml{++} to add
theorems to a simpset.  This is useful when you are developing a
theory.

For example, the following three methods are equivalent, except that the
first two create a reusable component {\tt SUMML\_ss}.  The example is a
taken from the longer example at the end of this chapter.
\begin{verbatim}
val SUMML_ss = rewrites [SUMM_TAKE_LEFT,SUMM_1,SUMM_0];
val summl_ss = mk_simpset [HOL_ss, SUMML_ss];

val SUMML_ss = rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
val summl_ss = hol_ss ++ SUMML_ss;

val summl_ss = hol_ss ++ rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
\end{verbatim}
In general you should strive to build simpsets which solve/normalise a
particular class of terms rather than creating simpsets on-the-fly.

\section{An example: List Equality}

The following example shows how to add rewrites to an existing simpset
and apply the simpset to prove simple results.  The simpset is made up
of a simple rewrite about lists, added to the basic reasoning
facilities in {\tt bool\_ss}.  The final line indicates that these
rewrites are actually already present in the built-in simpset {\tt
hol\_ss}.  {\tt hol\_ss} contains powerful arithmetic reasoning
simplification strategies and it is a workhorse simpset for many
verifications.
\begin{boxed} \begin{verbatim}
- load "simpLib";     (* load the simplification library *)
  load "boolSimps";   (* contains bool_ss *)
  load "listTheory";  (* the theory of lists *)

- open simpLib listTheory;
  infix ++;

- CONS_11;
val it = |- !h h' t t'. (CONS h t = CONS h' t') = (h = h')

- SIMP_CONV boolSimps.bool_ss [CONS_11]  (Parse.Term`[x;y] = [1;2]`);
val it = |- ([x; y] = [1; 2]) = (x = 1) /\ (y = 2) : thm

- load "HOLSimps";  (* A simpset for some common theories *)
  open HOLSimps;

- SIMP_PROVE hol_ss [] (Parse.Term`~([1;2;4] = [1;2;3])`);
val it = |- ~([1; 2; 4] = [1; 2; 3]) : thm
\end{verbatim} \end{boxed}
Here is the trace produced when tracing is turned on at a low level:
\begin{boxed} \begin{verbatim}
- Trace.trace_level := 1;

- SIMP_PROVE hol_ss [] (Parse.Term`~([1;2;4] = [1;2;3])`);
  rewriting [1; 2; 4] = [1; 2; 3] with
    |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
  rewriting 1 = 1 with |- (x = x) = T
  rewriting [2; 4] = [2; 3] with
    |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
  rewriting 2 = 2 with |- (x = x) = T
  rewriting [4] = [3] with
    |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
  4 = 3 via cache hit! simplifies to: F
  rewriting [] = [] with |- (x = x) = T
  rewriting F /\ T with |- F /\ t = F
  rewriting T /\ F with |- T /\ t = t
  rewriting T /\ F with |- T /\ t = t
  rewriting ~F with |- ~F = T
val it = |- ~([1; 2; 4] = [1; 2; 3]) : thm
\end{verbatim} \end{boxed}


\section{Built In Simpsets}


Some useful simpset fragments are included in the simplifier library.
These are based on existing HOL theories.  They can automate a large
amount of ``trivial reasoning'' about HOL constructs that previously
needed special treatment.
\begin{boxed}
\begin{verbatim}
   boolSimps.BOOL_ss     : ssdata
   boolSimps.CONG_ss     : ssdata
   boolSimps.NOT_ss      : ssdata
   pairSimps.PAIR_ss     : ssdata
   sumSimps.SUM_ss       : ssdata
   combinSimps.COMBIN_ss : ssdata
   listSimps.list_ss     : ssdata
   ListSimps.LIST_ss     : ssdata
   arithSimps.ARITH_ss   : ssdata
   UnwindSimps.UNWIND_ss : ssdata
   SatisfySimps.SATISFY_ss : ssdata
\end{verbatim}
\end{boxed}
\begin{description}
\item[{\tt BOOL\_ss}] The basic rewrites dealing with the boolean connectives
  plus automatic beta conversion, and a couple of other trivial
  theorems.

\item[{\tt CONG\_ss}] Contains two very useful congruences, that
  support contextual reasoning in the presence of implications and
  conditional expressions.  This ``simpset fragment'' combines with
  {\tt BOOL\_ss} to make the {\tt bool\_ss} simpset.

\item[{\tt NOT\_ss}] Rewrites for pushing negations inward, and for
  simplifying disjunctions involving negations.

\item[{\tt PAIR\_ss}] The useful rewrites from the core ``pair''
  theory.

\item[{\tt SUM\_ss}] The useful rewrites from the ``sum'' theory,
  including conditional rewrites for {\tt INR} and {\tt OUTR}.

\item[{\tt COMBIN\_ss}] Standard theorems about K, S, I, o from the
  ``combin'' theory.

\item[{\tt list\_ss}] The most useful rewrites from the ``list''
  theory.  Will reduce {\tt MAP}, {\tt APPEND}, {\tt EVERY} and so
  on, where they are applied to concrete lists.

\item[{\tt LIST\_ss}] The most useful rewrites from the ``List''
  library, as well as those from the ``list'' theory.

\item[{\tt UNWIND\_ss}] Contains {\tt UNWIND\_FORALL\_CONV} and {\tt
    UNWIND\_EXISTS\_CONV} for eliminating trivial universal and
  existential quantifications.

\item[{\tt SATISFY\_ss}] Does one-level (non-searching) prolog style
  unification to help eliminate obvious existential quantifiers.  This
  is useful to help guess unknowns in side conditions.

\item[{\tt ARITH\_ss}] This is the most powerful of the basic
  simpset fragments.  It has the following features:
  \begin{itemize}
  \item {\tt ARITH} is applied as a decision procedure
    on all propositions that it may solve.
  \item This application of {\tt ARITH} is ``context-aware'', in the
    sense that any context from the assumption list (when using {\tt
      ASM\_SIMP\_TAC}) or that has been collected via congruence rules
    (e.g from the left-hand-side of an implication) which is
    arithmetic is given to {\tt ARITH\_CONV} as well.
  \item {\tt ARITH} is also used to collect linear like-terms together
    within formulae.  This is implemented via first symbolically
    evaluating the formulae with an ML calculator, then using {\tt
      ARITH\_CONV} to prove that the original formula equals this
    result.
  \item Calls to {\tt ARITH} are cached.
  \end{itemize}

\item[{\tt HOL\_ss}] This merges the fragments from {\tt BOOL\_ss},
  {\tt CONG\_ss}, {\tt NOT\_ss}, {\tt PAIR\_ss},
  {\tt SUM\_ss}, {\tt COMBIN\_ss}, {\tt SATISFY\_ss},
  {\tt UNWIND\_ss}, {\tt ARITH\_ss}, and {\tt LIST\_ss}.
\end{description}

All of the above objects are {\em simpset fragments}, not simpsets.
Two actual simpsets are premade from these:
\begin{boxed} \begin{verbatim}
   val HOLSimps.hol_ss : simpset
   val boolSimps.bool_ss : simpset
\end{verbatim} \end{boxed}
{\tt hol\_ss} is made by combining all of the simpset fragments listed
above; indeed, it is directly constructed from {\tt HOL\_ss}.  This is
what most users will initially use.

%{\tt bool\_ss} contains {\tt BOOL\_ss} and {\tt CONG\_ss}.  Using it is
%akin to using {\tt REWRITE\_TAC}, except that contextual rewriting using
%congruence rules for implications and conditional expressions is also
%performed.

Notice that the above simpset fragments dwell in independent
structures. This allows the simplifier library to be used to work in a
theory without creating dependencies on extraneous theories. For
example, {\tt ARITH\_ss} can be used without making the theory of lists
an ancestor theory. This supports clean formalizations.

\section{The Simplification Functions}

The basic routines used to invoke simplification are:
\begin{boxed} \begin{verbatim}
    val SIMP_CONV : simpset -> thm list -> conv
    val SIMP_PROVE : simpset -> thm list -> term -> thm
    val SIMP_RULE : simpset -> thm list -> thm -> thm
    val SIMP_TAC : simpset -> thm list -> tactic
    val ASM_SIMP_TAC : simpset -> thm list -> tactic
    val FULL_SIMP_TAC : simpset -> thm list -> tactic
\end{verbatim} \end{boxed}

In the examples below the theorems and definitions come from the
theories ``List'' and ``arithmetic'' except where noted.

\ml{SIMP\_CONV} makes a simplification conversion from the given
simpset.  The theorems in the second argument are used as additional
rewrites. The conversion uses a top-depth strategy for rewriting. It
sets both the solver and the depther to be \ml{SIMP\_CONV} itself.
\ml{SIMP\_CONV} never fails, though it may diverge.  Beware of
divergence when trying to solve conditions to conditional rewrites.
Examples of its use are:
\begin{verbatim}
- SIMP_CONV hol_ss [] (--`TL[SUC 0;1 + 4; 2 * (3 + 2) + m]`--);
val it = |- TL [SUC 0; 1 + 4; 2 * (3 + 2) + m] = [5; m + 10] : thm

- open arithmeticTheory;
  SIMP_CONV hol_ss [LEFT_ADD_DISTRIB] (--`2 * (b + c) + a`--);
val it = |- 2 * (b + c) + a = a + 2 * b + 2 * c : thm
- SIMP_CONV hol_ss [] (--`(b + c + a) + d = (a + b) + (c + d)`--);
val it = |- ((b + c + a) + d = (a + b) + c + d) = T : thm
\end{verbatim}

\ml{SIMP\_PROVE} invokes \ml{SIMP\_CONV} and then strips off the
\ml{= T} at the end of the theorem. For example:
\begin{verbatim}
- SIMP_PROVE hol_ss [] (--`(b + c + a) + d = (a + b) + (c + d)`--);
val it = |- (b + c + a) + d = (a + b) + c + d : thm
- SIMP_PROVE hol_ss [] (--`!m n p. (p + m = p + n) = (m = n)`--);
val it = |- !m n p. (p + m = p + n) = m = n : thm
\end{verbatim}

\ml{SIMP\_RULE} invokes \ml{CONV\_RULE} with the conversion generated
by \ml{SIMP\_CONV} using the given simpset and additional rewrites. For
example:
\begin{verbatim}
- open ListTheory;
  val th = SPEC (--`CONS (h:'a) t`--) LENGTH_BUTLAST;
val th =
  |- ~(CONS h t = []) ==>
     (LENGTH (BUTLAST (CONS h t)) = PRE (LENGTH (CONS h t))) : thm
- SIMP_RULE hol_ss [] th;
val it = |- LENGTH (BUTLAST (CONS h t)) = PRE (LENGTH t + 1) : thm
\end{verbatim}
Now, we would like to end up with \ml{LENGTH t} on the right hand side
instead of \ml{PRE (LENGTH t + 1)}. We could try the following:
\begin{verbatim}
- SIMP_RULE hol_ss [prim_recTheory.PRE] th;
val it = |- LENGTH (BUTLAST (CONS h t)) = PRE (LENGTH t + 1) : thm
\end{verbatim}
However, this doesn't work: the rules in \ml{hol\_ss} rewrite \ml{SUC n} to
\ml{n + 1}, and \ml{PRE} only works on \ml{SUC n}. One solution is to
create a simpset that doesn't include the arithmetic simplification:
\begin{verbatim}
val lss = mk_simpset [boolSimps.BOOL_ss, ListSimps.LIST_ss];
= val lss = - : simpset
- SIMP_RULE lss [prim_recTheory.PRE] th;
val it = |- LENGTH (BUTLAST (CONS h t)) = LENGTH t : thm
\end{verbatim}

\ml{SIMP\_TAC} makes a simplification tactic from the given simpset
and additional rewrite theorems. The tactic uses a top-depth strategy
for rewriting, and will be recursively reapplied when a simplification
step makes a change. Basically, it invokes \ml{CONV\_TAC} with the
conversion generated by \ml{SIMP\_CONV} using the given simpset and
additional rewrites. Here is an example of using \ml{SIMP\_TAC} (the
definitions are given below in Section \ref{extended-example}):
\begin{verbatim}
- set_goal ([], --`!f n. (SUMM f n n = f n)`--);
val it =
  Status: 1 proof.
  1. Incomplete:
       Initial goal:
       ``!f n. SUMM f n n = f n``
   : proofs
- e (SIMP_TAC hol_ss [summ_DEF,SUMM_DEF]);
OK..
1 subgoal:
val it =
  ``!f n. summ (\k. f (k + n)) 1 = f n``
   : goalstack
\end{verbatim}

\ml{ASM\_SIMP\_TAC} takes the terms in the assumption list,
\ml{ASSUME}s them, and adds them to the list of theorems used for
rewriting. The assumptions are also added to the context that will be
passed to conversions.

\ml{FULL\_SIMP\_TAC} simplifies the assumptions one by one, before
simplifying the goal.  The assumptions are simplified in the order
that they are found in the assumption list, and the simplification
of each assumption is used when simplifying the next assumption.

\section{Rewrite Rules}

\label{rewrite-rules}

Rewrite rules are theorems which express an equality.  They
are similar to the theorems
provided as input to the `plain' rewriter
\ml{REWRITE\_TAC}.  Some examples are:
\begin{hol}\begin{verbatim}
   |- !i j k. (i + j) + k = i + (j + k)
   |- HD (CONS h t) = h
   |- NULL [] = T
   |- (!x. t) = t
\end{verbatim}\end{hol}
In each of the rules above, an infinite number of potential
reductions has been specified.  For example the first rule
will act on any term which matches \ml{(--`($i$ + $j$) + $k$`--)}.

Rewrite rules may also be {\em conditional}.  For example:
\begin{hol}\begin{verbatim}
EL_CONS |- n > 0 ==> (EL n (CONS h t) = EL (n-1) t)
\end{verbatim}\end{hol}
This
rule applies to any term which matches \ml{(--`EL $n$ (CONS $h$ $t$)`--)},
and will only be applied if the condition \ml{(--`$n$ > 0`--)} can be
solved for a particular $n$.  Note that solving an arithmetic side condition
like this automatically will almost certainly
require a decision procedure to be present.

A bit of care has to be taken when formulating conditional rewrites.
For example, say we want to use the fact that the function {\tt MAP2}
preserves the length of lists. One possible way to phrasing the
theorem is
\begin{hol} \begin{verbatim}
MY_LENGTH_MAP2 |- !f m l1 l2. (LENGTH l1 = m) /\ (LENGTH l2 = m) ==>
                  (LENGTH (MAP2 f l1 l2) = m)
\end{verbatim} \end{hol}

However, this will not work as a congruence rule. In a proper rewrite
rule, the variables in the right hand side of the consequent must be
contained in the variables on the left hand side. It is not sufficient
that the values can be determined by the conditions. Thus the rule
must be reformulated, for example as:
\begin{hol} \begin{verbatim}
LENGTH_MAP2 |- !l1 l2.
               (LENGTH l1 = LENGTH l2) ==>
               (!f. (LENGTH (MAP2 f l1 l2) = LENGTH l1) /\
                    (LENGTH (MAP2 f l1 l2) = LENGTH l2))
\end{verbatim} \end{hol}


\subsection{How rewrite rules are made}

Strictly speaking, each reduction rule in a simpset must specify an
equality. However, any theorem which is not already an
equality can be turned into a rewrite rule by simply
converting \ml{|- $t$} to \ml{|- $t$ = T}.
In fact, the process is a little more complex than this.
All theorems are processed by a {\em rewrite maker}
before being added to a simpset.  The rewrite maker is
an attribute of the simpset.  The default rewrite maker
performs the following transformations repeatedly:
\begin{itemize}
    \item A conjunction in the final conclusion lead to
    two reduction rules.  Thus
\begin{hol} \begin{verbatim}
       |- ... ==> x /\ y becomes
       |- ... ==> x and
       |- ... ==> y.
\end{verbatim} \end{hol}

    \item Negations \ml{~$t$} in the final conclusion become \ml{$t$ = F}:
    \begin{hol} \begin{verbatim}
       |- ... ==> ~t becomes
       |- ... ==> (t = F).
\end{verbatim} \end{hol}

    \item Universal quantifiers get stripped off the
    conclusion:
    \begin{hol} \begin{verbatim}
       |- ... ==> !x. t becomes
       |- ... ==> t.
\end{verbatim} \end{hol}

    \item Ignoring conditions, a rewrite rule whose conclusion
    is not an equality, universal quantification,
    negation or conjunction becomes one rewrite rule:
    \begin{hol} \begin{verbatim}
       |- ... ==> x becomes
       |- ... ==> (x = T).
\end{verbatim} \end{hol}

    \item All side conditions are transformed into a single condition,
    where variables free in the condition but not in the equality
    become existentially quantified.  Thus
    \begin{hol} \begin{verbatim}
       |- IS_TYPE t ==> PROG x t ==> IS_PROG x becomes
       |- (?t. IS_TYPE t /\ PROG x t) ==> (IS_PROG x = T)
\end{verbatim} \end{hol}
\end{itemize}

Note that in general, some decision procedure or external routine must
be contained in the simpset in order to automatically choose an
appropriate value for these existential variables.  Two routines are
provided in {\tt HOL\_ss} to handle this --- \ml{SATISFY} and
\ml{UNWIND\_EXISTS\_CONV}.

\subsection{How rewrite rules are applied}

Simplification works by:
\begin{itemize}
    \item Descending the target term in a top-down
fashion.
    \item At each subterm, the simplifier attempts to match
the current subterm with one of the rewrite
rules from the simpset.  This is done
efficiently by using term nets to eliminate most
non-matches.
    \item When a match is found, the simplifier attempts
to solve the conditions to the rewrite rule.  It does this
by trying to simplify the conditions to the term \verb%"T"%.
    \item If the conditions are solved, then the rewrite rule is applied and
the process continues on the new term.
\end{itemize}

This is a somewhat simplified view of things - the exact term traversal
performed is dictated by the congruence rules being used - this is
explained further in Section~\ref{congruence-rules}.


\subsection{Matching and Higher Order Matching}

For a rewrite rule \ml{|- $c_1$ ==> \ldots ==> $t_1$ = $t_2$},
the simplifier will try to match subterms against $t_1$.  The
matching performed is a limited version of {\it higher order
matching}.  For many rewrite rules this will have no effect.  However,
wherever function valued variables are free in $t_1$, then higher
order matching may come into play.

Higher order matching allows a pattern such as
\ml{(--`!x. P x`--)} to match a term like \ml{(--`(!x. x = 3)`--)}.  In
this example the variable $P$ will be instantiated to
\verb%(--`\x. x = 3`--)%.
Higher order matching allows rewrite rules to be far more expressive.
For example, beta reduction can be expressed as a rewrite rule:
\begin{hol} \begin{verbatim}
   |- (\x. P x) y = P y
\end{verbatim} \end{hol}
Some other common higher order rewrite rules are:
\begin{hol} \begin{verbatim}
   |- ~(!x. P x) = (?x. ~P x)
   |- (!x. P x /\ Q) = (!x. P x) /\ Q
   |- (!x. P x /\ Q x) = (!x. P x) /\ (!x. Q x)
\end{verbatim} \end{hol}
All of the quantifier movement conversions from Section~{quantifier-movement}\
can be implemented using higher order rewrite rules.

The limited higher order matching used in the simplifier
only allows function variables in the match to be parameterised
by variables which are quantified in the pattern.  Thus \ml{(--`P x`--)}
will not match \ml{(--`x = 3`--)}, whereas \ml{(--`?x. P x`--)} will.
This ensures unique unifiers as the unifiers can be made maximal
over these variables.  This
avoids many of the difficulties that arise with full higher order
matching.  Note, however, that the simplifier
is sufficiently programmable to allow
other kinds of matching to be used instead of higher order matching.

The higher order matching routines used by the simplifier are also available
for general use by other derived procedures.  The relevant functions
are in the structure {\tt Ho\_match}.


\section{Contextual Rewriting}

The discussion so far has assumed that the simplifier reduces
a term by traversing its subterms in a simple top-depth fashion.  This
is how `plain rewriting' works in the \HOL\ system.  In
this simple case, reductions
made to subterms are justified by the {\it congruence rules}:
$$\Gamma_1\turn l_1=l_2\qquad\qquad\qquad\Gamma_2\turn r_1=r_2\over
\Gamma\turn l_1\ r_1 = l_2\_r_2$$
$$\Gamma_1\turn t_1=t_2\over
\Gamma\turn (\lquant{x}t_1) = (\lquant{x}t_2)$$
which are in turn implemented by the conversional \ml{SUB\_CONV}.

This process is straight forward to implement, but fails to do justice to the
fact that, when reducing certain subterms, it is desirable
to make use of additional facts which hold
locally.  These `context theorems' can be used
in the rewrite process, or can be provided as extra input to
local calls to decision procedures.

To take a simple yet important example, consider
the case when reducing the term $t_2$ within \ml{(--`$t_1$ ==> $t_2$`--)}.
It is reasonable to expect that an automatic tool can make use of any rewrite
rules that can be derived from $t_1$ when simplifying $t_2$.
In other words, $t_1$ is added to the ``current working context'' when
within $t_2$. \footnote{The notion of context turns out to be an important one
in theorem proving work, and provides one of the
motivations for the Window Inference proof style (see the
\HOL\ window inference library for more details on this).
Simplification can be seen as the fully automated, and thus
less controlled, version of window inference, restricted to the equality
relation.}

As an example, consider the goal
\begin{verbatim}
       (--`P x /\ ~(x = y) ==> ~([1;x;5] = [1;y;5])`--)
\end{verbatim}
goal is obviously true, but may require several tactics to solve
in the primitive \HOL\ system.

The key observation is that when reducing the term on the right of the
implication, the ``theorems'' \ml{|- P x} and \ml{|- ~(x = y)} can
be assumed.  During simplification, they are added as
rewrites to the current simpset.  They are also added to the
working context of any co--operating decision procedures, but that
will be described in more detail later.

To see this in practice, try:
\begin{boxed} \begin{verbatim}
- SIMP_PROVE hol_ss [CONS_11]
  (--`P x /\ ~(x = y) ==> ~([1;x;5] = [1;y;5])`--);
val it = |- ~[1;x;5] = [1;y;5] : thm
\end{verbatim} \end{boxed}


\section{Ordered Rewriting}

\label{ordered-rewriting}

It is well known that some rewrite rules cause `plain rewriting'
(i.e. \ml {REWRITE\_TAC}) to loop, for instance:
\begin{hol} \begin{verbatim}
ADD_SYM |- x + y = y + x
INSERT_SYM |- x INSERT (y INSERT s) = y INSERT (x INSERT s)
\end{verbatim} \end{hol}
Both of these are {\em permutative rewrites}, in the sense that
the right hand side is a permutation of the pattern on the left.

For such rewrites, the simplifier uses the common and
simple solution of only applying these rewrites when the term
to which they are being applied is strictly reduced according to a term
ordering.

Ordered rewriting will also work for operations whose
commutative theorems have side conditions, as for partial functions:
\begin{hol} \begin{verbatim}
PUPDATE_SYM |- ~(x1 = x2) ==>
               (PUPDATE (x1,y1) (PUPDATE (x2,y2) f) =
                PUPDATE (x2,y2) (PUPDATE (x1,y1) f))
\end{verbatim} \end{hol}

\subsection{AC Rewriting}

The \HOL\ simplifier supports AC (associative/commutative) rewriting,
in the style of the Isabelle simplifier.  This will create a
normaliser for repeated applications of an associative/commutative
operator like \ml{+}.\footnote{Note that \HOL\ also includes AC\_CONV
for performing similar operations.}

To enable AC ordered rewriting, the associativity and commutativity theorems
for the operation must be inserted in a simpset by making a \ml{ssdata}
object and merging it with an existing simpset. For example, to enable
AC rewriting over \ml{+}:
\begin{hol} \begin{verbatim}
ADD_ASSOC |- x + (y + z) = (x + y) + z
ADD_SYM |- x + y = y + x
\end{verbatim} \end{hol}
must be inserted in to a simpset:\footnote{Note that
the theorem \ml{ADD\_SYM} is misnamed in \HOL.  It refers
to the commutativity of addition, and so should be called
\ml{ADD\_COMM}.
Symmetry is a notion that should only be used for relations such as
{\tt =}.}
\begin{boxed} \begin{verbatim}
- val ac_ss = bool_ss ++ SIMPSET {ac =[(ADD_ASSOC,ADD_SYM)],
                                  convs=[],dprocs=[],filter=NONE,rewrs=[],
                                  congs=[]};

- SIMP_CONV ac_ss ``(y + x) + 3 + 6 + (2 * x + 1)``;
val it = |- (y + x) + 3 + 6 + (2 * x + 1) =
            1 + 3 + 6 + y + x + 2 * x : thm

- SIMP_CONV ac_ss ``x + 3 + y + 2 * x + 6 + 1``;
val it = |- x + 3 + y + 2 * x + 6 + 1 =
            1 + 3 + 6 + y + x + 2 * x : thm

- SIMP_PROVE ac_ss ``(y + x) + 3 + 6 + (2 * x + 1) =
                           x + 3 + y + 2 * x + 6 + 1``;
val it = |- (y + x) + 3 + 6 + (2 * x + 1) =
            x + 3 + y + 2 * x + 6 + 1 : thm
\end{verbatim} \end{boxed}


This is implemented using ordered rewriting, with a term ordering that
is AC compatible.    Three rewrite rules are needed to implement AC
rewriting:
\begin{hol} \begin{verbatim}
ADD_SYM |- x + y = y + x
GSYM ADD_ASSOC |- (x + y) + z = x + (y + z)
ADD_LCOMM |- x + (y + z) = y + (x + z)
\end{verbatim} \end{hol}
The simplifier derives the third of these from the first two.
Also, note that the standard form for \HOL\ associativity theorems is the
wrong way round for the purposes of normalising AC nestings to
the right --- the simplifier reverses this automatically.


\section{Tracing}

Simplification often involves many, many inferences, and complex
paths of deduction may occur, leading to almost magical results.
There is a down side to this - simplification is difficult
to understand, and even more difficult to debug when things
go wrong.

The value provided to control tracing is:
\begin{boxed} \begin{verbatim}
   val Trace.trace_level : int ref
\end{verbatim} \end{boxed}
The trace levels currently range from 0 to 5, where level
0 is no tracing and level 5 presents enormous quantities of information.
The aim has been to make trace level 1 produce sufficient information
to debug most problems.  Trace levels 3 to 5 should only be needed
when debugging the simplifier itself.



\section{Decision Procedures and Simplification}

It is exceptionally useful to allow the integration {\it decision
procedures} with the simplification process, particularly arithmetic
decision procedures.

In the context of this discussion, a decision procedure is a function
which performs complex computation before producing a reduction for a
term.  The example we shall use is \ml{ARITH}, which determines the
truth of linear arithmetic formulae over the natural numbers.  It is
easy to imagine decision procedures for other domains such as the
integer and real numbers.

Decision procedures are integrated into the simplification process by
adding them to simpsets.  They get invoked at low priority, in the sense
that all reductions via rewrite rules are performed before trying the
procedure on a term.  All decision procedures are invoked for every
reducible subterm.

See the examples in the source code for how to add a decision procedure
to a simpset.

\section{Congruence Rules}

\label{congruence-rules}

We now fill in the details of the general process we have outlined
above.  During simplification, facts get added to the current working
context because of the application of {\em congruence rules}.  The user
is encouraged to learn to recognise when a certain construct allows
additional crucial assumptions to be made when simplifying subterms, and
to learn how to express this fact by a congruence rule.

Congruence rules are contained within simpsets.  User congruence rules
are usually theorems, although congruence rules may also be ML functions
(these are potentially useful for infinite families of congruence rules,
and are used for highly speed critical congruence rules such as those
for equality).


\subsection{Constructing Congruence Rules}

Some sample congruence rules are:
\begin{hol} \begin{verbatim}
COND_CONG |- (g = g') ==>
             (g'  ==> (t = t')) ==>
             (~g' ==> (e = e')) ==>
             ((g => t | e) = (g' => t' | e'))

RES_FORALL_CONG |- (R = R') ==>
                   (!x. R' x ==> (P x = P' x)) ==>
                   ((!x::R. P x) = (!x::R'. P' x))
\end{verbatim} \end{hol}
These theorems are not hard to prove.
The principal difficulty is in {\it formulating} the rules
in the first place.  The simplifier only accepts
congruence rules formulated in a certain way.
We shall examine the process of formulating
the first congruence rule in some detail.

The purpose of a congruence rule is to state how a certain construct is
simplified by simplifying its subterms.  The place to begin is with a
`template' of the construct to be simplified.  In this case we are
interested in simplifying conditionals, thus the template is \ml{(--`$g$
=> $t$ | $e$`--)}.

Next, the final conclusion of the congruence rule
must state that the free subterms $g$, $t$ and $e$ get simplified, and
that the term produced is equal to the term we started with.
Thus the final conclusion is
\begin{hol} \begin{verbatim}
COND_CONG |- ... ==>
             ((g => t | e) = (g' => t' | e'))

\end{verbatim} \end{hol}
Next, the antecedents to this final conclusion specify how these
variables are related.  They are
interpreted as instructions by the simplifier about the order
in which the subterms should be simplified, and what context assumptions may be
made for each subterm.
The first antecedent is simple enough: $g = g'$.  The simplifier
interprets this as ``first starting with $g$, simplify it and get a new
$g'$''.  The second is more complex: \ml{$g'$ ==> ($t$ = $t'$)}.
This is interpreted as ``simplify $t$ to some $t'$, adding the
fact $g'$ to the current context''.  In other words, the antecedent
says that it is valid to assume $g'$ when simplifying $t$.
The third antecedent is similar: \ml{~$g$ ==> ($e$ = $e'$)}.  This
allows the introduction of the context assumption \ml{~$g$}.

After all three antecedents have been processed and discharged by the
simplifier, a theorem {\tt |- ($g$ => $t$ | $e$) = ($g'$ => $t'$ | $e'$}
will have been produced, where the values for $g'$, $t'$ and $e'$ have
been discovered by contextual simplification.  This theorem is then used
by the simplifier to help reduce the entire term.

Putting all this together gives the general congruence rule:
\begin{hol} \begin{verbatim}
COND_CONG |- (g = g') ==>
             (g'  ==> (t = t')) ==>
             (~g' ==> (e = e')) ==>
             ((g => t | e) = (g' => t' | e'))
\end{verbatim} \end{hol}

\subsection{Bad congruence rules}

Ill-formed congruence rules (i.e. congruence rules not in the form
specified above) will cause unpredictable and incorrect behaviour.  The
user should study examples of congruence rules, consult the relevant
manual sections and communicate with other \HOL\ users should this be a
problem.


\section{Avoiding the Pitfalls of Simplification}

Simplification is a powerful theorem proving technique, but is prone to
several major problems.  This section is designed to make the user aware
of these in advance!

The pitfalls of simplification can generally be
avoided by two techniques:
\begin{itemize}
   \item Using well designed simpsets.
   \item Using tracing extensively.
\end{itemize}
The behaviour of simplification is almost totally dependent on the
simpset being used.  The user should stop and think about
exactly what reduction behaviour they are specifying when they
group together certain theorems, conversions and decision
procedures.  A well designed simpset will work on a particular
class of problems, and in many cases will do a thorough job
of proving simple facts within that domain.  A poorly
designed simpset constructed by throwing together random
theorems will create all sorts of problems at a later date.

\subsection{Non-termination}

Simplification will continue until no more reductions apply.  It is very
easy to create simpsets which will result in non-termination when
applied to some terms.  \HOL\ detects some simple cases of
non-terminating rewrites (e.g. it doesn't admit rewrites like \ml{|- x =
I x} since the pattern on the left occurs within the right).  However,
there is no general protection against this.  Generally problems arise
when two or more theorems interact to produce looping, such as \ml{|- x
> y = y < x} and \ml{y < x = x > y}.

The best way to avoid non-termination is to ask the following question
about each rewrite you place in a simpset: {\it Is the rewrite actually
contributing toward bringing terms toward a particular normal form}.
For example, the rewrite \ml{|- x > y = y < x} should only be added to a
simpset if the normal form we are heading for involves only instances of
\ml{<} for all linear inequalities.

\subsection{Backward Chaining}

Conditional rewriting allows a limited degree of search when
rewriting, since the rewrite is not applied unless all conditions
are solved.  The simplifier itself is used to solve these
conditions.  This will often lead to looping if
theorems which contain the pattern within the conditions
are added as rewrite rules.  The most obvious example is
transitivity theorems:
\begin{hol} \begin{verbatim}
    |- (?z. x < z /\ z < y) ==> x < y
\end{verbatim} \end{hol}
Do not put these theorems into simpsets!

\subsection{Non-confluence}

When faced with a choice of two rewrite rules, both of which are
applicable to a given term, the simplifier will choose one and ignore
the other.  This can lead to {\em confluence} problems, i.e. it may be
that a different final result will be produced depending on the order in
which rewrites are applied.  Non-confluence is mainly a problem for the
long term maintainability of proofs.

Some simpsets may be confluent regardless of the presence of conflicting
rewrite rules.  An extensive literature exists on term rewriting system
and their properties such as termination and confluence, which the user
is encouraged to study if the subject proves particularly important.

An example of non-confluence is given by the rewrites:
\begin{hol} \begin{verbatim}
<example>
\end{verbatim} \end{hol}

\subsection{Over-applicability}

Consider the following potential rewrite rule, taken from
the underlying theory for the abstract theory of groups:
\begin{hol} \begin{verbatim}
    |- (?G. GROUP (G,prod) /\ G x /\ G y /\ G z) ==>
       (prod (prod x y) z = prod x (prod y z))
\end{verbatim} \end{hol}
The theorem simply states that if $G$ and $prod$ are
together define a algebraic group, then $prod$ is associative.
Note there are no constants apart from \ml{GROUP} --- $G$ and
$prod$ are variables.

The problem with such a rewrite rule is that the pattern
\ml{(--`prod (prod x y) z`--)} will produce many undesirable matches.
The problem is that the rewrite rule is over applicable.  The
best solution at the moment is to make the intent of the rule
more clear, by replacing \ml{(--`prod`--)} with a function
to compute \ml{(--`prod`--)} for a given group:
\begin{hol} \begin{verbatim}
    |- GROUP (G,prod) /\ G x /\ G y /\ G z ==>
       (PROD (G,prod) (PROD (G,prod) x y) z =
        PROD (G,prod) x (PROD (G,prod) y z))
\end{verbatim} \end{hol}
The pattern \ml{(--`PROD (G,prod) (PROD (G,prod) x y) z`--)} will
now be suitably applicable.  The use of \ml{PROD} may seem
redundant, but turns out to be a suitable generalisation.

\section{Summary}

To summarise the main points of this document:
\begin{itemize}
    \item A powerful contextual, conditional simplifier is available
    through the functions \ml{SIMP\_CONV}, \ml{SIMP\_RULE},
    \ml{SIMP\_TAC}, \ml{ASM\_SIMP\_TAC} etc.
    \item Rewrite rules are organised in objects called {\it simpsets}.
    The best simpsets are generally created by making small simpsets and
    combining them with other simpset fragments to form powerful tools.
    \item Rewrite rules are applied using a limited form of higher
    order matching.  Higher order matching allows general theorems about
    functionals such as quantifiers to be applied without the use
    of purpose built conversions.
    \item Simpsets may also contain congruence rules.  Congruence
    rules dictate the term traversal strategy used during simplification
    and the cause the production of context theorems
    \item Simpsets may contain conversions which can act as infinite sets
    of rewrite rules.  This is useful for conversion schemas
    which are essentially reduction but which cannot be formulated
    as rewrite rules (e.g. \ml{REDUCE\_CONV}).
    \item Simpsets may contain decision procedures.  These are invoked
    at lowest priority, and have access to the current working
    context.  The arithmetic decision procedure included with
    \ml{arith\_ss} is an example of the use of this.
\end{itemize}

\section{An extended example}
\label{extended-example}

\begin{verbatim}

new_theory "summ";
infix ++;
Trace.trace_level := 1;

val summ_DEF = new_recursive_definition {
    def=(--`(summ f 0 = 0) /\
            (summ f (SUC n) = f n + summ f n)`--),
    fixity=Prefix,
    name="summ_DEF",
    rec_axiom=prim_recTheory.num_Axiom};

(* now define the normal notion of summation *)

val SUMM_DEF = new_definition("SUMM_DEF",
    (--`SUMM f n m = summ (\k. f(n+k)) ((m+1)-n)`--));

(* The following is the actual way we want to define this - we could do this *)
(* with TFL.  For now we'll just axiomatise it. *)
val summ = mk_thm([],
    (--`(!f. summ f 0 = 0) /\
        (!f n. n > 0 ==> (summ f n = f 0 + (summ (\k. f (k+1)) (n-1))))`--));


val SUMM_0 = prove((--`!f n m. (n = m + 1) ==> (SUMM f n m = 0)`--),
    SIMP_TAC hol_ss [summ,SUMM_DEF]);
val SUMM_1 = prove((--`!f n m. (n = m) ==> (SUMM f n m = f n)`--),
    SIMP_TAC hol_ss [summ,SUMM_DEF]);
val SUMM_TAKE_LEFT = prove(
    (--`!f n m. (n < m) ==> (SUMM f n m = f n + SUMM f (n+1) m)`--),
    SIMP_TAC hol_ss [SUMM_DEF,summ]);

(* here's an example of using SIMP_TAC several times along with
   small helper theorems *)
local
    val thm = SIMP_PROVE hol_ss []
        (--`(n < m) ==> ((m + 1) - n = SUC (m - n))`--)
in
val SUMM_TAKE_RIGHT = TAC_PROOF
    (([], --`!f n m. (n < m) ==> (SUMM f n m = SUMM f n (m-1) + f m)`--),
     SIMP_TAC hol_ss [SUMM_DEF, summ_DEF] THEN
     SIMP_TAC bool_ss [thm, summ_DEF] THEN
     SIMP_TAC hol_ss [summ_DEF])
end;

(* sum from left - much more efficient as it uses addition not subtraction *)
val SUMML_ss = rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
val summl_ss = hol_ss ++ SUMML_ss;

val SUMMR_ss = rewrites [SUMM_TAKE_RIGHT, SUMM_1,SUMM_0];
val summr_ss = hol_ss ++ SUMMR_ss;


(*-------------------------------------------------------------------------
 * SUMM_x = |- !n. n >= 1 ==> (2 * SUMM (\x. x) 1 n = (n + 1) * n) : thm
 *-----------------------------------------------------------------------*)

add_theory_to_sml "arithmetic";

val SUMM_x = prove(
    (--`!n. n >= 1 ==> (2*(SUMM (\x.x) 1 n) = (n + 1) * n)`--),
    INDUCT_TAC
    THENL [
       FULL_SIMP_TAC summr_ss [],
       ASM_CASES_TAC (--`n=0`--) THEN
       ASM_SIMP_TAC summr_ss [LEFT_ADD_DISTRIB,RIGHT_ADD_DISTRIB]
    ]);


(*-------------------------------------------------------------------------
 * Using SIMP_CONV as a calculator for Sums
 *-----------------------------------------------------------------------*)

clear_arith_caches();
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 10`--);
SIMP_CONV summr_ss [] (--`2 * SUMM (\x. x) 1 10`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 15`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 20`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 30`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 40`--);


SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 2`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 3`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 4`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 5`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 6`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 7`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*y*y) 1 3`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*y*y) 1 10`--);
\end{verbatim}

\end{document}

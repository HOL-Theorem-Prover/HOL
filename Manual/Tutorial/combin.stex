\newcommand{\eos}{\hfill{}$\cdots\diamond\cdots$\hfill{}\vspace{5mm}}

\newcommand{\mathpredn}{\mathbin{-\!\!\!\mid\mid\!\rightarrow}}

\newcommand{\KC}{\con{K}}
\newcommand{\SC}{\con{S}}
\newcommand{\bk}{\char'134}


\chapter{Example: Combinatory Logic}
\label{chap:combin}

\section{Introduction}
\label{sec:Introduction}

This small case study is a formalisation of (variable-free)
combinatory logic.  This logic is of foundational importance in
theoretical computer science, and has a very rich theory.  The example
builds principally on a development done by Tom Melham.  The complete
script for the development is available as \texttt{clScript.sml} in
the \texttt{examples/ind\_def} directory of the distribution.  It is
self-contained and so includes the answers to the exercises set at the
end of this document.

The \HOL{} sessions assume that the Unicode trace is \emph{on} (as it is by default), meaning that even though the inputs may be written in pure ASCII, the output still uses nice Unicode output (symbols such as $\forall$ and $\Rightarrow$).
The Unicode symbols could also be used in the input.


\section{The type of combinators}
\label{sec:Type-Combinators}

The first thing we need to do is define the type of \emph{combinators}.
There are just two of these, \KC{} and \SC, but we also need to be able to \emph{combine} them, and for this we need to introduce the notion of application.
For lack of a better ASCII symbol, we will use the hash (\#) to represent this in the logic.
Finally, we will start by ``hiding'' the names \holtxt{S} and \holtxt{K} so that the constants of these names from the existing \HOL{} theories won't interfere with parsing.
\setcounter{sessioncount}{0}
\begin{session}
\begin{alltt}
>>_ hide "K"; hide "S";
>> Datatype: cl = K | S | # cl cl
   End
\end{alltt}
\end{session}
We also want the \# to be an infix, so we set its fixity to be a tight
left-associative infix:
\begin{session}
\begin{alltt}
>> set_fixity "#" (Infixl 1100);
\end{alltt}
\end{session}


% C = S (S (K S) (S (K K) S)) (K K)


\section{Combinator reductions}
\label{sec:Comb-Reduct}

Combinatory logic is the study of how values of this type can evolve
given various rules describing how they change.  Therefore, our next
step is to define the reductions that combinators can undergo.  There
are two basic rules:
\[\begin{array}{l@{\;\;\rightarrow\;\;}l}
\KC\;x\;y & x\\
\SC\;f\;g\;x & (f x)(g x)
\end{array}\]
Here, in our description outside of HOL, we use juxtaposition instead
of the \#.  Further, juxtaposition is also left-associative, so that
$\con{K}\;x\;y$ should be read as $\con{K}\;\#\;x\;\#\;y$ which is in
turn $(\con{K}\;\#\;x)\;\#\;y$.

Given a term in the logic, we want these reductions to be able to fire
at any point, not just at the top level, so we need two further
congruence rules:\[
\begin{array}{l}
\infer{x\;y\;\;\rightarrow\;\;x'\;y}{x\;\;\rightarrow\;\;x'}\\[5mm]
\infer{x\;y\;\;\rightarrow\;\;x\;y'}{y\;\;\rightarrow\;\;y'}
\end{array}\]
In HOL, we can capture this relation with an inductive definition.
First we need to set our arrow symbol up as an infix to make everything that bit prettier.
The \ml{set\_mapped\_fixity} function lets the arrow be our surface syntax, but maps to the name \holtxt{redn} underneath.
Making constants have pure alphanumeric names is generally a good idea.
\begin{session}
\begin{alltt}
>> set_mapped_fixity {fixity = Infix(NONASSOC, 450),
                      tok = "-->", term_name = "redn"};
\end{alltt}
\end{session}
We make our arrow symbol non-associative, thereby making it a
parse error to write \verb!x --> y --> z!.
It would be nice to be able to write this and have it mean \verb!x --> y /\ y --> z!, but this is not presently possible with the HOL parser.

Our next step is to actually define the relation, using the \ml{Inductive} syntax.
Using the provided stem \ml{redn} as a base, the underlying facility proves a number of theorems for us, and shows us three: \ml{redn\_rules}, \ml{redn\_ind}, \ml{redn\_cases}.
These theorems are available in the \ML{} session under those names, and are also saved under those names when the theory is exported.
\begin{session}
\begin{alltt}
>> Inductive redn:
     (!x y f. x --> y   ==>    f # x --> f # y) /\
     (!f g x. f --> g   ==>    f # x --> g # x) /\
     (!x y.   K # x # y --> x) /\
     (!f g x. S # f # g # x --> (f # x) # (g # x))
   End
\end{alltt}
\end{session}

Using the \ml{redn\_rules} theorem we can demonstrate single steps of our reduction relation:
\begin{session}
\begin{alltt}
>> PROVE [redn_rules] ``S # (K # x # x) --> S # x``;
\end{alltt}
\end{session}
The system we have just defined is as powerful as the
$\lambda$-calculus, Turing machines, and all the other standard models
of computation.

One useful result about the combinatory logic is that it is
\emph{confluent}.  Consider the term $\SC\;z\;(\KC\;\KC)\;(\KC\; y\;
x)$.  It can make two reductions, to $\SC\;z\;(\KC\;\KC)\;y$ and also
to $(z\;(\KC\;y\;x))\,(\KC\;\KC\;(\KC\;y\;x))$.  Do these two choices
of reduction mean that from this point on the terms have two
completely separate histories?  Roughly speaking, to be confluent
means that the answer to this question is \emph{no}.


\section{Transitive closure and confluence}
\label{sec:Transitive-Clos-Conf}

A notion crucial to that of confluence is that of \emph{transitive
  closure}.  We have defined a system that evolves by specifying how
an algebraic value can evolve into possible successor values in one
step.  The natural next question is to ask for a characterisation of
evolution over one or more steps of the $\rightarrow$ relation.

In fact, we will define a relation that holds between two values if
the second can be reached from the first in zero or more steps.  This
is the \emph{reflexive, transitive closure} of our original relation.
However, rather than tie our new definition to our original relation,
we will develop this notion independently and prove a variety of
results that are true of any system, not just our system of
combinatory logic.

So, we begin our abstract digression with another inductive definition.
Our new constant is \con{RTC}, such that $\con{RTC}\;R\;x\;y$ is true if it is possible to get from $x$ to $y$ with zero or more ``steps'' of the $R$ relation.
(The standard notation for $\con{RTC}\;R$ is $R^*$; we will see \HOL{} try to approximate this with the text \holtxt{R\^{}*}.)
We can express this idea with just two rules.
The first
\[ \infer{\con{RTC}\;R\;x\;x}{} \]
says that it's always possible to get from $x$ to $x$ in zero or more steps.
The second \[
\infer{\con{RTC}\;R\;x\;z}{R\;x\;y\qquad\con{RTC}\;R\;y\;z}
\]
says that if you can take a single step from $x$ to $y$, and then take zero or more steps to get $y$ to $z$, then it's possible to take zero or more steps to get between $x$ and $z$.
The realisation of these rules in HOL is again straightforward.

(As it happens, \con{RTC} is already a defined constant in the context we're working in (it is found in \texttt{relationTheory}), so we'll hide it from view before we begin.
We thus avoid messages telling us that we are inputting ambiguous terms.
The ambiguities would always be resolved in the favour of more recent definition, but the warnings are annoying.
We inherit the nice syntax for the old constant with our new one.)
\begin{session}
\begin{alltt}
>> val _ = hide "RTC";

>> Inductive RTC:
    (!x.     RTC R x x) /\
    (!x y z. R x y /\ RTC R y z ==> RTC R x z)
   End
\end{alltt}
\end{session}
Now let us go back to the notion of confluence.  We want this to mean
something like: ``though a system may take different paths in the
short-term, those two paths can always end up in the same place''.
This suggests that we define confluent thus:
\begin{session}
\begin{alltt}
>> Definition confluent_def:
     confluent R =
       !x y z. RTC R x y /\ RTC R x z ==>
               ?u. RTC R y u /\ RTC R z u
   End
\end{alltt}
\end{session}
This property states of $R$ that we can ``complete the diamond'';
if we have
\begin{center}
\begin{tikzpicture}[scale=.8,transform shape]
\node (middle) {};
\node (x) [above=of middle] {$x$};
\node (y) [left=of middle] {$y$};
\node (z) [right=of middle] {$z$};
\path (x) edge [->,thick] node[auto,swap] {$*$} (y);
\path (x) edge [->,thick] node[auto] {$*$} (z);
\end{tikzpicture}
\end{center}
then we can complete with a fresh value $u$:
\begin{center}
\begin{tikzpicture}[scale=.8,transform shape]
\node (middle) {};
\node (x) [above=of middle] {$x$};
\node (y) [left=of middle] {$y$};
\node (z) [right=of middle] {$z$};
\node (u) [below=of middle] {$u$};
\path (x) edge [->,thick] node[auto,swap] {$*$} (y);
\path (x) edge [->,thick] node[auto] {$*$} (z);
\path (y) edge [->,thick,densely dotted] node[auto,swap] {$*$} (u);
\path (z) edge [->,thick,densely dotted] node[auto] {$*$} (u);
\end{tikzpicture}
\end{center}

One nice property of confluent relations is that from any one starting
point they produce no more than one \emph{normal form}, where a normal
form is a value from which no further steps can be taken.
\begin{session}
\begin{alltt}
>> Definition normform_def:  normform R x = !y. ~R x y
   End
\end{alltt}
\end{session}
In other words, a system has an $R$-normal form at $x$ if there are no
connections via $R$ to any other values.  (We could have written
\verb!~?y. R x y! as our RHS for the definition above.)

We can now prove the following:
\begin{session}
\begin{alltt}
>> g `!R. confluent R ==>
          !x y z.
            RTC R x y /\ normform R y /\
            RTC R x z /\ normform R z ==> (y = z)`;
\end{alltt}
\end{session}
We rewrite with the definition of confluence:
\begin{session}
\begin{alltt}
>> e (rw[confluent_def]);
\end{alltt}
\end{session}
    Our confluence property is now assumption 0, and we can use it to
    infer that there is a $u$ at the base of the diamond:
\begin{session}
\begin{alltt}
>> e (`?u. RTC R y u /\ RTC R z u` by metis_tac []);
\end{alltt}
\end{session}
    So, from $y$ we can take zero or more steps to get to $u$ and
    similarly from $z$.  But, we also know that we're at an $R$-normal
    form at both $y$ and $z$.  We can't take any steps at all from
    these values.  We can conclude both that $u = y$ and $u = z$, and
    this in turn means that $y = z$, which is our goal.  So we can
    finish with
\begin{session}
\begin{alltt}
>> e (metis_tac [normform_def, RTC_cases]);
\end{alltt}
\end{session}
Packaged up so as to remove the sub-goal package commands, we can
prove and save the theorem for future use by:
\begin{session}
\begin{alltt}
>> Theorem confluent_normforms_unique:
     !R. confluent R ==>
         !x y z. RTC R x y /\ normform R y /\
                 RTC R x z /\ normform R z ==> y = z
   Proof
     rw[confluent_def] >>
     `?u. RTC R y u /\ RTC R z u` by metis_tac [] >>
     metis_tac [normform_def, RTC_cases]
   QED
\end{alltt}
\end{session}
\eos{}

Clearly confluence is a nice property for a system to have.  The
question is how we might manage to prove it.
Let's start by defining the diamond property that we used in the definition of confluence.
We'll again hide the existing definition of ``diamond'':
\begin{session}
\begin{alltt}
>> val _ = hide "diamond";
>> Definition diamond_def:
     diamond R = !x y z. R x y /\ R x z ==> ?u. R y u /\ R z u
   End
\end{alltt}
\end{session}
    Now we clearly have that confluence of a relation is equivalent to
    the reflexive, transitive closure of that relation having the
    diamond property.
\begin{session}
\begin{alltt}
>> Theorem confluent_diamond_RTC:
      !R. confluent R = diamond (RTC R)
   Proof   rw[confluent_def, diamond_def]
   QED
\end{alltt}
\end{session}
So far so good.
How then do we show the diamond property for $\con{RTC}\;R$?  The answer that leaps to mind is to hope that if the original relation has the diamond property, then maybe the reflexive and transitive closure will too.
The theorem we want is \[
  \con{diamond}\;R \;\Rightarrow\; \con{diamond}\,(\con{RTC}\;R)
\]
Graphically, this is hoping that from \[
  \xymatrix @R=5mm @C=2.5mm {
& x \ar[dl] \ar[dr] & \\
y \ar@{.>}[dr] & & z \ar@{.>}[dl] \\
& u}\]
 we will be able to conclude\[\xymatrix @R=4mm @C=2mm {
& & & x \ar[dl] \ar[dr] & \\
& & y \ar@{.>}[dr] \ar@{-->}[ddll] & & z \ar@{.>}[dl] \ar@{-->}[ddrr] \\
& & & u \\
p \ar@{.>}[dddrrr] & & & & & & q \ar@{.>}[dddlll] \\ \\ \\
& & & r}
\]
where the dashed lines indicate that these steps (from $x$ to $p$, for example) are using $\con{RTC}\;R$.
The presence of two instances of $\con{RTC}\;R$ is an indication that this proof will require two inductions.
With the first we will prove
\[\xymatrix @R=4mm @C=2mm {
& & & x \ar[dl] \ar[dr] & \\
& & y \ar@{.>}[dr] \ar@{-->}[ddll] & & z \ar@{.>}[dl] \\
& & & u \ar@{.>}[ddll] \\
p \ar@{.>}[dr] \\
& r}\]
In other words, we want to show that if we take one step in one
direction (to $z$) and many steps in another (to $p$), then the
diamond property for $R$ will guarantee us the existence of $r$,
to which will we be able to take many steps from both $p$ and $z$.

We state the goal so we can easily strip away the outermost assumption (that $R$ has the diamond property) before beginning the rule induction.%
\footnote{%
  In this and subsequent proofs using the sub-goal package, we will present the proof manager as if the goal to be proved is the first ever on this stack.
  In other words, we have done a \texttt{dropn 1;} after every successful proof to remove the evidence of the old goal.
  In practice, there is no harm in leaving these goals on the proof manager's stack.}
\begin{session}
\begin{alltt}
>>__ dropn 1;
>> g `!R. diamond R ==>
          !x p z. RTC R x p /\ R x z ==>
                  ?u. RTC R p u /\ RTC R z u`;
\end{alltt}
\end{session}
First, we strip away the diamond property assumption (two things need to be stripped: the outermost universal quantifier and the antecedent of the implication).
If we use \ml{rw} at this point, we strip away too much so we have to be more precise and use the lower level tool \ml{strip\_tac}.
This tactic will remove a universal quantification, an implication or a conjunction:
\begin{session}
\begin{alltt}
>> e (strip_tac >> strip_tac);
\end{alltt}
\end{session}
Now we can use the induction principle for reflexive and transitive closure (alternatively, we perform a ``rule induction'').
To do this, we use the \ml{Induct\_on} command that is also used to do
structural induction on algebraic data types (such as numbers and
lists).
We provide the name of the constant whose induction principle we want
to use, and the tactic does the rest:
\begin{session}
\begin{alltt}
>> e (Induct_on `RTC`);
\end{alltt}
\end{session}
Let's strip the goal as much as possible with the aim of making what
remains to be proved easier to see:
\begin{session}
\begin{alltt}
>> e (rw[]);
\end{alltt}
\end{session}
This first goal is easy.  It corresponds to the case where the many
steps from $x$ to $p$ are actually no steps at all, and $p$ and $x$
are actually the same place.  In the other direction, $x$ has taken
one step to $z$, and we need to find somewhere reachable in zero or
more steps from both $x$ and $z$.  Given what we know so far, the only
candidate is $z$ itself.
In fact, we don't even need to provide this witness explicitly: \texttt{metis\_tac} will find it for us, as long as we tell it what the rules governing \con{RTC} are:
\begin{session}
\begin{alltt}
>> e (metis_tac [RTC_rules]);
\end{alltt}
\end{session}
And what of this remaining goal?
Assumptions one and four between them are the top of an $R$-diamond.
Let's use the fact that we have the diamond property for $R$ and infer that there exists a $v$ to which $x'$ and $z$ can both take single steps:
\begin{session}
\begin{alltt}
>> e (`?v. R x' v /\ R z v` by metis_tac [diamond_def]);
\end{alltt}
\end{session}
Now we can apply our induction hypothesis (assumption 3) to complete
the long, lop-sided strip of the diamond.
We will conclude that there is a $u$ such that $R^*\;p\;u$ and $R^*\;v\;u$.
We actually need a $u$ such that $\con{RTC}\;R\;z\;u$, but because there is a single $R$-step between $z$ and $v$ we have that as well.
All we need to provide \texttt{metis\_tac} is the rules for \con{RTC}:
\begin{session}
\begin{alltt}
>> e (metis_tac [RTC_rules]);
##assert can top_thm()
\end{alltt}
\end{session}
Again we can (and should) package up the lemma, avoiding the sub-goal package commands:
\begin{session}
\begin{alltt}
##eval Theorem R_RTC_diamond:
         !R. diamond R ⇒
             !x p z. RTC R x p ∧ R x z ⇒
                     ∃u. RTC R p u ∧ RTC R z u
       Proof
         strip_tac >> strip_tac >> Induct_on `RTC` >> rw[]
         >- metis_tac [RTC_rules]
         >- (`?v. R x' v /\ R z v` by metis_tac [diamond_def] >>
             metis_tac [RTC_rules])
       QED
\end{alltt}
\end{session}
\eos{}

Now we can move on to proving that if $R$ has the diamond property, so too does $R^*$.
We want to prove this by induction again.
We state the goal as the obvious \[
\con{diamond}\;R\;\Rightarrow\;\con{diamond}\,(R^*)
\]
expecting to strip away the LHS of the goal as an assumption (which will feed into the lemma we just proved), and to perform another ``RTC-induction'' on what the second \holtxt{diamond} expands into:
\begin{session}
\begin{alltt}
>>__ dropn 1;
>> g `!R. diamond R ==> diamond (RTC R)`;
\end{alltt}
\end{session}
So, we begin by stripping away the diamond property assumption.
Then, we expand with the definition of \holtxt{diamond} in the goal.
\begin{session}
\begin{alltt}
>> e (strip_tac >> strip_tac >> simp[diamond_def]);
\end{alltt}
\end{session}
We see that the simplifier has kept the diamond-assumption untouched, but has exposed two \holtxt{RTC} terms in the goal.
In order to make it clear that we wish to induct on the first, we can write a more elaborate pattern when we induct:
\begin{session}
\begin{alltt}
>> e (Induct_on `RTC R x y` >> rw[]);
\end{alltt}
\end{session}
The first goal is again an easy one, corresponding to the case where
the trip from $x$ to $y$ has been one of no steps whatsoever.
\begin{session}
\begin{alltt}
>> e (metis_tac [RTC_rules]);
\end{alltt}
\end{session}
This goal is very similar to the one we saw earlier.  We have the top
of a (``lop-sided'') diamond in assumptions 1 and 4, so we can infer
the existence of a common destination for $x'$ and $z$:
\begin{session}
\begin{alltt}
>> e (`?v. RTC R x' v /\ RTC R z v` by metis_tac [R_RTC_diamond]);
\end{alltt}
\end{session}
    At this point in the last proof we were able to finish it all off
    by just appealing to the rules for \con{RTC}.  This time it is not
    quite so straightforward.  When we use the induction hypothesis
    (assumption 3), we can conclude that there is a $u$ to which both
    $y$ and $v$ can connect in zero or more steps, but in order to
    show that this $u$ is reachable from $z$, we need to be able to
    conclude $R^*\;z\;u$ when we know that
    $R^*\;z\;v$ (assumption 6 above) and
    $R^*\;v\;u$ (our consequence of the inductive
    hypothesis).  We leave the proof of this general result as an
    exercise, and here assume that it is already proved as the theorem
    \texttt{RTC\_RTC}.
\begin{session}
\begin{alltt}
>>__ Theorem RTC_RTC:
       !R x y z. RTC R x y /\ RTC R y z ==> RTC R x z
     Proof
       gen_tac >> Induct_on `RTC R x y` >> metis_tac [RTC_rules]
     QED
>> e (metis_tac [RTC_rules, RTC_RTC]);
\end{alltt}
\end{session}
We can now package up our desired result:
\begin{session}
\begin{alltt}
##eval Theorem diamond_RTC:
         !R. diamond R ==> diamond (RTC R)
       Proof
         strip_tac >> strip_tac >> simp[diamond_def] >>
         Induct_on `RTC R x y` >> rw[]
         >-  metis_tac[RTC_rules]
         >- (`?v. RTC R x' v /\ RTC R z v` by metis_tac[R_RTC_diamond] >>
             metis_tac [RTC_RTC, RTC_rules])
       QED
\end{alltt}
\end{session}

\section{Back to combinators}
\label{sec:Return-to-Land}

Now, we are in a position to return to the real object of study and
prove confluence for combinatory logic.  We have done an abstract
development and established that\[
\begin{array}{ccccc}
\con{diamond}\;R & \Rightarrow & \con{diamond}\,(\con{RTC}\;R)\\
& & \land\\
& & \con{diamond}\,(\con{RTC}\;R) & \equiv & \con{confluent}\;R\\
\end{array}
\]
(We have also established a couple of other useful results along the way.)

\newcommand{\topk}{\KC\;\SC\;(\KC\;\KC\;\KC)} Sadly, it just isn't the
case that $\rightarrow$, our one-step relation for combinators, has
the diamond property.
A counter-example is $\topk$.
Its possible evolution can be described graphically:
\[\xymatrix @R=5mm @C=2.5mm {
& \topk \ar[dl] \ar[dr] & \\
\SC & & \KC\;\SC\;\KC \ar[dl] \\
& \SC}\]
If we had the diamond property, it should be possible to find a common
destination for $\KC\;\SC\;\KC$ and $\SC$.  However, \SC{} doesn't
admit any reductions whatsoever, so there isn't a common
destination.\footnote{In fact our counter-example is more complicated
  than necessary.  The fact that $\KC\;\SC\;\KC$ has a
  reduction to the normal form $\SC$ also acts as a counter-example.
  Can you see why?}

This is a problem.  We are going to have to take another approach.
We will define another reduction strategy (\emph{parallel reduction}),
and prove that its reflexive, transitive closure is actually the same
relation as our original's reflexive and transitive closure.  Then we
will also show that parallel reduction has the diamond property.  This
will establish that its reflexive, transitive closure has it too.
Then, because they are the same relation, we will have that the
reflexive, transitive closure of our original relation has the diamond
property, and therefore, our original relation will be confluent.

\subsection{Parallel reduction}
\label{sec:Parallel-Reduction}

Our new relation allows for any number of reductions to occur in parallel.
We use the \texttt{-||->} symbol to indicate parallel reduction because of its own parallel lines, and use \holtxt{predn} to name the constant:
\begin{session}
\begin{alltt}
>> set_mapped_fixity {tok = "-||->", fixity = Infix(NONASSOC, 450),
                      term_name = "predn"};
\end{alltt}
\end{session}
Then we can define parallel reduction itself.
The rules look very similar to those for $\rightarrow$.
The difference is that we allow the reflexive transition, and say that an application of $x\;u$ can be transformed to $y\;v$ if there are transformations taking $x$ to $y$ and $u$ to $v$.
This is why we must have reflexivity incidentally.
Without it, a term like $(\KC\;x\;y)\,\KC$ couldn't reduce because while the LHS of the application ($\KC\;x\;y$) can reduce, its RHS (\KC) can't.
\begin{session}
\begin{alltt}
>>_ Inductive predn:
      (!x. x -||-> x) /\
      (!x y u v. x -||-> y /\ u -||-> v
                        ==>
                 x # u -||-> y # v) /\
      (!x y. K # x # y -||-> x) /\
      (!f g x. S # f # g # x -||-> (f # x) # (g # x))
    End
\end{alltt}
\end{session}

\subsection{Using \con{RTC}}
\label{sec:Using-RTC}

Now we can set up nice syntax for the reflexive and transitive closures of our two relations.
We will use ASCII symbols for both that consist of the original symbol followed by an asterisk.
Note also how, in defining the two relations, we have to use the \texttt{\$} character to ``escape'' the symbols' usual fixities.
This is exactly analogous to the way in which ML's \texttt{op} keyword is used.
First, we create the desired symbol for the concrete syntax,
and then we ``overload'' it so that the parser will expand it to the
desired form.
\begin{session}
\begin{alltt}
>> set_fixity "-->*" (Infix(NONASSOC, 450));

>> Overload "-->*" = “RTC redn”;
\end{alltt}
\end{session}
We do exactly the same thing for the reflexive and transitive closure
of our parallel reduction.
\begin{session}
\begin{alltt}
>> set_fixity "-||->*" (Infix(NONASSOC, 450));

>> Overload "-||->*" = ``RTC predn``;
\end{alltt}
\end{session}
Incidentally, in conjunction with \texttt{PROVE} we can now
automatically demonstrate relatively long chains of reductions:
\begin{session}
\begin{alltt}
>> PROVE [RTC_rules, redn_rules] ``S # K # K # x -->* x``;

>> PROVE [RTC_rules, redn_rules]
    ``S # (S # (K # S) # K) # (S # K # K) # f # x -->*
      f # (f # x)``;
\end{alltt}
\end{session}
(The latter sequence is seven reductions long.)


\subsection{Proving the \con{RTC}s are the same}
\label{sec:Proving-RTCs-same}

We start with the easier direction, and show that everything in
$\rightarrow^*$ is in $\mathpredn^*$.  Because
\con{RTC} is monotone (which fact is left to the reader to prove),
we can reduce this to showing that $x\rightarrow y\Rightarrow x\mathpredn y$.

Our goal:
\begin{session}
\begin{alltt}
>>__ dropn 1;
>> g `!x y. x -->* y ==> x -||->* y`;
\end{alltt}
\end{session}
We back-chain using our monotonicity result:
\begin{session}
\begin{alltt}
>>__ Theorem RTC_monotone:
       !R1 R2. (!x y. R1 x y ==> R2 x y) ==>
               (!x y. RTC R1 x y ==> RTC R2 x y)
     Proof
       ntac 3 strip_tac >> Induct_on `RTC` >>
       metis_tac [RTC_rules]
     QED
>> e (match_mp_tac RTC_monotone);
\end{alltt}
\end{session}
Now we can induct over the rules for $\rightarrow$:
\begin{session}
\begin{alltt}
>> e (Induct_on `x --> y`);
\end{alltt}
\end{session}
We could split the 4-way conjunction apart into four goals, but there
is no real need.  It is quite clear that each follows immediately from
the rules for parallel reduction.
\begin{session}
\begin{alltt}
>> e (metis_tac [predn_rules]);
\end{alltt}
\end{session}
Packaged into a tidy little sub-goal-package-free parcel, our proof is
\begin{session}
\begin{alltt}
##eval Theorem RTCredn_RTCpredn:
         !x y. x -->* y   ==>   x -||->* y
       Proof
         match_mp_tac RTC_monotone >>
         Induct_on `x --> y` >> metis_tac [predn_rules]
       QED
\end{alltt}
\end{session}
\eos{}

Our next proof is in the other direction.  It should be clear that we
will not just be able to appeal to the monotonicity of \con{RTC} this
time; one step of the parallel reduction relation can not be mirrored
with one step of the original reduction relation.  It's clear that
mirroring one step of the parallel reduction relation might take many
steps of the original relation.  Let's prove that then:
\begin{session}
\begin{alltt}
>>__ dropn 1;
>> g `!x y. x -||-> y   ==>   x -->* y`;
\end{alltt}
\end{session}
This time our induction will be over the rules defining the parallel
reduction relation.
\begin{session}
\begin{alltt}
>> e (Induct_on `x -||-> y`);
\end{alltt}
\end{session}

There are four conjuncts here, and it should be clear that all but the second can be proved immediately by appeal to the rules for the transitive closure and for $\rightarrow$ itself.
So, we split apart the conjunctions, use a \texttt{THEN1} to discharge the first subgoal, thus putting the second subgoal into focus to be be dealt with more carefully. Note that \texttt{>-} is sugar for \texttt{THEN1}.
\begin{session}
\begin{alltt}
>> e (rpt conj_tac >- metis_tac[RTC_rules, redn_rules]);
\end{alltt}
\end{session}
What of this sub-goal?
If we look at it for long enough, we should see that it is another monotonicity fact.
More accurately, we need what is called a \emph{congruence} result for \holtxt{-->*}.
In this form, it's not quite right for easy proof.
Let's go away and prove \texttt{RTCredn\_ap\_monotonic} separately.
(Another exercise!)
Our new theorem should state
\begin{session}
\begin{verbatim}
Theorem RTCredn_ap_congruence:
  !x y. x -->* y ==> !z. x # z -->* y # z /\ z # x -->* z # y
Proof  ...
QED
>>__ Theorem RTCredn_ap_congruence:
       !x y. x -->* y ==> !z. x # z -->* y # z /\ z # x -->* z # y
     Proof Induct_on `RTC` >> metis_tac [RTC_rules, redn_rules]
     QED
\end{verbatim}
\end{session}
    Now that we have this, our sub-goal is almost immediately
    provable.  Using it, we know that \[\begin{array}{c}
      x\;x' \rightarrow^* y\;x' \\
      y\;x' \rightarrow^* y\;y'
    \end{array}\]
    All we need to do is ``stitch together'' the two transitions above
    and go from $x\;x'$ to $y\;y'$.  We can do this by appealing to our
    earlier \texttt{RTC\_RTC} result.
\begin{session}
\begin{alltt}
>> e (metis_tac [RTC_RTC, RTCredn_ap_congruence]);
\end{alltt}
\end{session}
But given that we can finish off what we thought was an awkward branch
with just another application of \texttt{metis\_tac}, we don't need to
use our fancy branching footwork at the stage before.  Instead, we
can just merge the theorem lists passed to both invocations, dispense
with the \texttt{rpt~conj\_tac} and have a very short tactic proof
indeed:
\begin{session}
\begin{alltt}
##eval Theorem predn_RTCredn:
         !x y. x -||-> y  ==>  x -->* y
       Proof
         Induct_on `x -||-> y` >>
         metis_tac [RTC_rules, redn_rules, RTC_RTC,
                    RTCredn_ap_congruence]
       QED
\end{alltt}
\end{session}
\eos{}

Now it's time to prove that if a number of parallel reduction steps
are chained together, then we can mirror this with some number of
steps using the original reduction relation.  Our goal:
\begin{session}
\begin{alltt}
>>__ dropn 1;
>> g `!x y. x -||->* y  ==> x -->* y`;
\end{alltt}
\end{session}
We use the appropriate induction principle to get to:
\begin{session}
\begin{alltt}
>> e (Induct_on `RTC`);
\end{alltt}
\end{session}
This we can finish off in one step.  The first conjunct is obvious,
and in the second the \verb!x -||-> y! and our last result combine to
tell us that \verb!x -->* y!.  Then this can be chained together with
the other assumption in the second conjunct and we're done.
\begin{session}
\begin{alltt}
>> e (metis_tac [RTC_rules, predn_RTCredn, RTC_RTC]);
\end{alltt}
\end{session}
Packaged up, this proof is:
\begin{session}
\begin{alltt}
##eval Theorem RTCpredn_RTCredn:
         !x y. x -||->* y   ==>  x -->* y
       Proof
         Induct_on `RTC` >>
         metis_tac [predn_RTCredn, RTC_RTC, RTC_rules]
       QED
\end{alltt}
\end{session}
\eos{}

Our final act is to use what we have so far to conclude that
$\rightarrow^*$ and $\mathpredn^*$ are equal.  We state our goal:
\begin{session}
\begin{alltt}
>>__ dropn 1;
>> g `$-||->* = $-->*`;
\end{alltt}
\end{session}
We want to now appeal to extensionality.  The simplest way to do this
is to rewrite with the theorem \texttt{FUN\_EQ\_THM}:
\begin{session}
\begin{alltt}
>> FUN_EQ_THM;
\end{alltt}
\end{session}
So, we rewrite:
\begin{session}
\begin{alltt}
>> e (rw[FUN_EQ_THM]);
\end{alltt}
\end{session}

This goal is an easy consequence of our two earlier implications.
\begin{session}
\begin{alltt}
>> e (metis_tac [RTCpredn_RTCredn, RTCredn_RTCpredn]);
\end{alltt}
\end{session}
Packaged, the proof is:
\begin{session}
\begin{alltt}
##eval Theorem RTCpredn_EQ_RTCredn:
         $-||->* = $-->*
       Proof rw [FUN_EQ_THM] >>
             metis_tac [RTCpredn_RTCredn, RTCredn_RTCpredn]
       QED
\end{alltt}
\end{session}


\subsection{Proving a diamond property for parallel reduction}
\label{sec:predn-diamond}

Now we just have one substantial proof to go.
Before we can even begin, there are a number of minor lemmas we will need to prove first.
These are basically specialisations of the theorem \texttt{predn\_cases}.
The problem with that theorem is that it is not easy to use as a rewrite or simplification rule: it would cause the simplifier to loop because there are instances of the left-hand-side pattern (\holtxt{x~-||->~y}) on its right-hand-side.
If we specialise the variable corresponding to the pattern's \holtxt{x}, then the looping can be removed.
In particular, we want exhaustive characterisations of the possibilities when the following terms undergo a parallel reduction:
$x\;y$, \KC, \SC, $\KC\;x$, $\SC\;x$, $\KC\;x\;y$, $\SC\;x\;y$ and
$\SC\;x\;y\;z$.

To do this, we will write a little function that derives
characterisations automatically:
\begin{session}
\begin{alltt}
>> fun characterise t = SIMP_RULE (srw_ss()) [] (SPEC t predn_cases);
\end{alltt}
\end{session}
The \ml{characterise} function specialises the theorem \ml{predn\_cases} with the input term, and then simplifies.
The \ml{srw\_ss()} simpset includes information about the injectivity and disjointness of constructors and eliminates obvious impossibilities.
For example,
\begin{session}
\begin{alltt}
>> val K_predn = characterise ``K``;

>> val S_predn = characterise ``S``;
\end{alltt}
\end{session}
Unfortunately, what we get back from other inputs is not so good:
\begin{session}
\begin{alltt}
>> val Sx_predn0 = characterise ``S # x``;
\end{alltt}
\end{session}
That first disjunct is redundant, as the following demonstrates:
\begin{session}
\begin{alltt}
##eval Theorem Sx_predn[local]:
         !x y. S # x -||-> y <=> ?z. y = S # z /\ x -||-> z
       Proof   rw[EQ_IMP_THM, Sx_predn0, predn_rules, S_predn]
       QED
\end{alltt}
\end{session}
Our \texttt{characterise} function will just have to help us in the
proofs that follow.
\begin{session}
\begin{alltt}
##eval Theorem Kx_predn[local]:
         !x y. K # x -||-> y <=> ?z. y = K # z /\ x -||-> z
       Proof   rw[characterise ``K # x``, predn_rules, K_predn, EQ_IMP_THM]
       QED
\end{alltt}
\end{session}
What of $\KC\;x\;y$?  A little thought demonstrates that there really
must be two cases this time.
\begin{session}
\begin{alltt}
##eval Theorem Kxy_predn[local]:
         !x y z.
              K # x # y -||-> z <=>
              (?u v. z = K # u # v /\ x -||-> u /\ y -||-> v) \/
              z = x
       Proof
         rw[EQ_IMP_THM, characterise ``K # x # y``, predn_rules, Kx_predn]
       QED
\end{alltt}
\end{session}
By way of contrast, there is only one case for $\SC\;x\;y$ because it
is not yet a ``redex'' at the top-level.
\begin{session}
\begin{alltt}
##eval Theorem Sxy_predn[local]:
         !x y z. S # x # y -||-> z <=>
                 ?u v. z = S # u # v /\ x -||-> u /\ y -||-> v
       Proof
         rw[characterise ``S # x # y``, predn_rules, EQ_IMP_THM, Sx_predn]
       QED
\end{alltt}
\end{session}
Next, the characterisation for $\SC\;x\;y\;z$:
\begin{session}
\begin{alltt}
##eval Theorem Sxyz_predn[local]:
         ∀w x y z. S # w # x # y -||-> z <=>
                   (∃p q r. z = S # p # q # r ∧
                            w -||-> p ∧ x -||-> q ∧ y -||-> r) ∨
                   z = (w # y) # (x # y)
       Proof
         rw[characterise ``S # w # x # y``, predn_rules, EQ_IMP_THM, Sxy_predn]
       QED
\end{alltt}
\end{session}
Last of all, we want a characterisation for $x\;y$.   What
\texttt{characterise} gives us this time can't be improved upon,
for all that we might look upon the four disjunctions and despair.
\begin{session}
\begin{alltt}
>> val x_ap_y_predn = characterise ``x # y``;
\end{alltt}
\end{session}
\eos{}

\noindent Now we are ready to prove the final goal.  It is
\begin{session}
\begin{alltt}
>>__ dropn 1;
>> g `!x y. x -||-> y ==>
            !z. x -||-> z ==> ?u. y -||-> u /\ z -||-> u`;
\end{alltt}
\end{session}
We now induct and split the goal into its individual conjuncts:
\begin{session}
\begin{alltt}
>> e (Induct_on `x -||-> y` >> rpt conj_tac);
\end{alltt}
\end{session}
The first goal is easily disposed of.  The witness we would provide
for this case is simply \texttt{z}, but \texttt{metis\_tac} will do
the work for us:
\begin{session}
\begin{alltt}
>> e (metis_tac [predn_rules]);
\end{alltt}
\end{session}
The next goal includes two instances of terms of the form \verb!x # y -||-> z!.
We can use our \verb!x_ap_y_predn! theorem here.
However, if we rewrite indiscriminately with it, we will really confuse the goal.
We want to rewrite just the assumption, not the instance underneath the existential quantifier.
Starting everything by repeatedly stripping can't lead us too far astray.
\begin{session}
\begin{alltt}
>> e (rw[]);
\end{alltt}
\end{session}
We need to split up assumption 4.  We can get it out of the assumption
list using the \ml{qpat\_x\_assum} theorem-tactical.
We will write
\begin{alltt}
##eval qpat_x_assum `_ # _ -||-> _`
         (strip_assume_tac o SIMP_RULE (srw_ss()) [x_ap_y_predn])
\end{alltt}
The quotation specifies the pattern that we want to match: we want the term that has an application term reducing, and as there is just one such, we can use ``don't care'' underscore patterns for the various arguments.
The second argument specifies how we are going to transform the theorem.
Reading the compositions from right to left, first we will simplify with the \verb!x_ap_y_predn! theorem (the simplifier invocation here is like that we used in the definition of the \ml{characterise} function), and then we will assume the result back into the assumptions, stripping disjunctions and existentials as we go.\footnote{%
  An alternative to using \ml{qpat\_x\_assum} is to use \texttt{by} instead: you would have to state the four-way disjunction yourself, but the proof would be more ``declarative'' in style, and though wordier, might be more maintainable.}

We already know that doing this is going to produce four new sub-goals (there were four disjuncts in the \verb!x_ap_y_predn! theorem).
We'll follow up the use of \ml{strip\_assume\_tac} with \ml{rw} to eliminate any equalities that might appear as assumptions.

So:
\begin{session}
\begin{alltt}
>>__ set_trace "Goalstack.howmany_printed_subgoals" 1;
>> e (qpat_x_assum `_ # _ -||-> _`
       (strip_assume_tac o SIMP_RULE (srw_ss()) [x_ap_y_predn]) >>
      rw[]);
\end{alltt}
\end{session}
This first sub-goal is an easy consequence of the rules for parallel reduction.
Because we've elided the somewhat voluminous output, we call \ml{p()} to print the next sub-goal again:
\begin{session}
\begin{alltt}
>>_ e (metis_tac[predn_rules]);
>> p();
\end{alltt}
\end{session}
This goal requires application of the two inductive hypotheses as well as the rules for parallel reduction, but is again straightforward for \ml{metis\_tac};
\begin{session}
\begin{alltt}
>>_ e (metis_tac[predn_rules]);
>> p();
\end{alltt}
\end{session}
Now our next goal (the third of the four) features a term \verb!K # z -||-> y! in the assumptions.
We have a theorem that pertains to just this situation.
But before applying it willy-nilly, let us try to figure out exactly what the situation is.
A diagram of the current situation might look like
\[\xymatrix @C=2cm {
*+<4pt>[F--]\txt{\fbox{\texttt{K\kern2mm \#\kern2mm z}} \texttt{\#} \fbox{\texttt{x'}}} \ar[r] & \txt{\texttt{z}} \ar@{.>}[d] \\
*+<4pt>[F--]\txt{\fbox{\texttt{y}} \texttt{\#} \fbox{\texttt{y'}}} \ar@{.>}[r] & \txt{\texttt{?u?}}
\ar "1,1"!<-12pt,0pt>;"2,1"!<-12pt,0pt>
\ar "1,1"!<28pt,0pt>;"2,1"!<11pt,0pt>
} \]
Our theorem tells us that \texttt{y} must actually be of the form \verb!K # w! for some \texttt{w}, and that there must be an arrow between \texttt{z} and \texttt{w}.
Thus:
\begin{session}
\begin{alltt}
>> e (`?w. (y = K # w) /\ (z -||-> w)` by metis_tac [Kx_predn]);
\end{alltt}
\end{session}
On inspection, it becomes clear that the \texttt{u} must be \texttt{w}.
The first conjunct requires \verb!K # w # y' -||-> w!, which we have because this is what \KC{}s do, and the second conjunct is already in the assumption list.
Rewriting (eliminating that equality in the assumption list first will make \ml{metis\_tac}'s job that much easier), and then first order reasoning will solve this goal:
\begin{session}
\begin{alltt}
>> e (rw [] >> metis_tac [predn_rules]);
\end{alltt}
\end{session}
This case involving \SC{} is analogous.  Here's the tactic to apply:
\begin{session}
\begin{alltt}
>> e (`?p q. (y = S # p # q) /\ (f -||-> p) /\ (g -||-> q)`
         by metis_tac [Sxy_predn] >>
      rw [] >> metis_tac [predn_rules]);
\end{alltt}
\end{session}
This next goal features a \verb!K # x # y -||-> z! term that we have a theorem for already.
Let's speculatively use a call to \texttt{metis\_tac} to eliminate the simple cases immediately (\verb!Kxy_predn! is a disjunct so we'll get two sub-goals if we don't eliminate anything).
\begin{session}
\begin{alltt}
>> e (rw[Kxy_predn] >> metis_tac[predn_rules]);
\end{alltt}
\end{session}
We got both cases immediately, and have moved onto the last case.
We can try the same strategy.
\begin{session}
\begin{alltt}
>> e (rw[Sxyz_predn] >> metis_tac [predn_rules]);
##assert can top_thm()
\end{alltt}
\end{session}
The final goal proof can be packaged into:
\begin{session}
\begin{alltt}
##eval Theorem predn_diamond_lemma[local]:
         !x y. x -||-> y ==>
               !z. x -||-> z ==> ?u. y -||-> u /\ z -||-> u
       Proof
         Induct_on ‘x -||-> y’ >> rpt conj_tac
         >- metis_tac [predn_rules]
         >- (rw[] >>
             qpat_x_assum ‘_ # _ -||-> _’
               (strip_assume_tac o SIMP_RULE std_ss [x_ap_y_predn]) >>
             rw[]
             >- metis_tac[predn_rules]
             >- metis_tac[predn_rules]
             >- (‘?w. (y = K # w) /\ (z -||-> w)’ by metis_tac [Kx_predn] >>
                 rw[] >> metis_tac [predn_rules])
             >- (‘?p q. (y = S # p # q) /\ (f -||-> p) /\ (g -||-> q)’ by
                    metis_tac [Sxy_predn] >>
                 rw [] >> metis_tac [predn_rules]))
         >- (rw[Kxy_predn] >> metis_tac [predn_rules])
         >- (rw[Sxyz_predn] >> metis_tac [predn_rules])
       QED
\end{alltt}
\end{session}
\eos{}

We are on the home straight.  The lemma can be turned into a statement
involving the \con{diamond} constant directly:
\begin{session}
\begin{alltt}
##eval Theorem predn_diamond:
         diamond predn
       Proof metis_tac [diamond_def, predn_diamond_lemma]
       QED
\end{alltt}
\end{session}

And now we can prove that our original relation is confluent in
similar fashion:

\begin{session}
\begin{alltt}
##eval Theorem confluent_redn:
         confluent redn
       Proof metis_tac [predn_diamond, confluent_diamond_RTC,
                        RTCpredn_EQ_RTCredn, diamond_RTC]
       QED
\end{alltt}
\end{session}



\section{Exercises}

If necessary, answers to the first three exercises can be found by
examining the source file in \texttt{examples/ind\_def/clScript.sml}.

\begin{enumerate}
\item Prove that \[\con{RTC}\;R \;x\; y \;\;\land \;\;
  \con{RTC}\;R\;y\;z\;\;\;\Rightarrow\;\;\; \con{RTC}\;R\;x\;z
\] You will need to prove the goal by induction, and will probably
  need to massage it slightly first to get it to match the appropriate
  induction principle.  Store the theorem under the name
  \texttt{RTC\_RTC}.
\item Another induction.  Show that \[
  (\forall x\,y.\; R_1\;x\;y\Rightarrow R_2\;x\;y) \Rightarrow
  (\forall x\,y.\; \con{RTC}\;R_1\;x\;y \Rightarrow \con{RTC}\;R_2\;x\;y)
\] Call the resulting theorem \texttt{RTC\_monotone}.
\item Yet another \con{RTC} induction, but where $R$ is no longer
  abstract, and is instead the original reduction relation.  Prove
\[
x \rightarrow^* y \;\;\;\Rightarrow\;\;\;
\forall z.\;\; x\;z \rightarrow^* y \;z \land
z\;x \rightarrow^* z\;y
\] Call it \texttt{RTCredn\_ap\_congruence}.

\item Come up with a counter-example for the following property: \[
\begin{array}{c}
  \left(
    \begin{array}{ll}
      \forall x\,y\,z. &
      R\;x\;y\;\;\land\;\; R\;x\;z \;\;\;\Rightarrow\\
      & \exists u.\;\con{RTC}\;R\;y\;u \;\;\land\;\;\con{RTC}\;R\;z\;u
      \end{array}\right)\\
    \Rightarrow\\
    \con{diamond}\;(\con{RTC}\;R)
  \end{array}
  \]
\end{enumerate}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "tutorial"
%%% End:

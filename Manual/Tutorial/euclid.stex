\chapter{Example: Euclid's Theorem}
\label{chap:euclid}

\setcounter{sessioncount}{0}

In this chapter, we prove in \holn{} that for every number, there is a prime number that is larger, \ie, that the prime numbers form an infinite sequence.
This proof has been excerpted and adapted from a much larger example due to John Harrison, in which he proved the $n = 4$ case of Fermat's Last Theorem.
The proof development is intended to serve as an introduction to performing high-level interactive proofs in \holn.%
\footnote{The proofs discussed below may be found in
\texttt{examples/euclid.sml} of the \HOL{} distribution.}
Many of the details may be difficult to grasp for the novice reader; nonetheless, it is recommended that the example be followed through in order to gain a true taste of using \HOL{} to prove non-trivial theorems.

Some tutorial descriptions of proof systems show the system performing amazing feats of automated theorem proving.
In this example, we have \textit{not} taken this approach; instead, we try to show how one actually goes about the business of proving theorems in \holn{}: when more than one way to prove something is possible, we will consider the choices; when a difficulty arises, we will attempt to explain how to fight one's way clear.

One `drives' \holn{} by interacting with the ML top-level loop, perhaps mediated \emph{via} an editor such as \texttt{emacs} or \texttt{vim}.
In this interaction style, ML function calls are made to bring in already-established logical context, \eg, \emph{via} \ml{load};
to define new concepts, \eg, \emph{via} \ml{Datatype},  \ml{Define}, and \ml{Hol\_reln};
and to perform proofs using the goalstack interface, and the proof tools from \ml{bossLib} (or if they fail to do the job, from lower-level libraries).

Let's get started.
First, we start the system, with the command \ml{<holdir>/bin/hol}.
We then ``\ml{open}'' the arithmetic theory; this means that all of the \ML{} bindings from the \HOL{} theory of arithmetic are made available at the top level.
\begin{session}
\begin{alltt}
>>_ open arithmeticTheory;
\end{alltt}
\end{session}
We now begin the formalization. In order to define the concept of
prime number, we first need to define the \emph{divisibility} relation:

\begin{session}
\begin{alltt}
>> Definition divides_def: divides a b = ?x. b = a * x
   End
\end{alltt}
\end{session}
Note how we are using ASCII notation to input our terms (\holtxt{?} is the ASCII way to write the existential quantifier), but the system responds with pleasant Unicode.
Unicode characters can also be used in the input.
Also note how equality on booleans gets printed as the if-and-only-if arrow, while equality on natural numbers stays as an equality.
The underlying constant is the same (equality) (as is implied by the fact that one can use \holtxt{=} in both places in the input), but the system tries to be helpful when printing.

The definition is added to the current theory with the name \ml{divides\_def}, and also available as an \ML{} binding with the name \ml{divides\_def}.
In the usual way of interacting with \HOL, such an \ML{} binding is made for each definition and (useful) proved theorem: the \ML{} environment is thus being used as a convenient place to hold definitions and theorems for later reference in the session.
Note that the \ml{Definition} syntax requires its keywords to be in column zero.

We want to treat \ml{divides} as a (non-associating) infix:
\begin{session}
\begin{verbatim}
>> set_fixity "divides" (Infix(NONASSOC, 450));
\end{verbatim}
\end{session}
Next we define the property of a number being \emph{prime}: a number $p$ is
prime if and only if it is not equal to $1$ and it has no divisors other
than $1$ and itself:

\begin{session}
\begin{alltt}
>> Definition prime_def:
     prime p <=> p <> 1 /\ !x. x divides p ==> (x=1) \/ (x=p)
   End
\end{alltt}
\end{session}
There is more ASCII syntax to observe here: \holtxt{\lt\gt} for not-equals, and \holtxt{!} for the universal quantifier.

That concludes the definitions to be made. Now we ``just'' have to prove
that there are infinitely many prime numbers. If we were coming to this
problem fresh, then we would have to go through a not-well-understood
and often tremendously difficult process of finding the right lemmas
required to prove our target theorem.\footnote{This is of course a
general problem in doing any kind of proof.} Fortunately, we are working
from an already completed proof and can devote ourselves to the far
simpler problem of explaining how to prove the required theorems.

\paragraph{Proof tools}
The development will illustrate that there is often more than one way to
tackle a HOL proof, even if one has only a single (informal) proof in
mind.
In this example, we often \emph{find} proofs by using the rewriter \ml{rw} to unwind definitions and perform basic simplifications, often reducing a goal to its essence.
\begin{session}
\begin{alltt}
>> rw;
\end{alltt}
\end{session}
When \ml{rw} is applied to a list of theorems, the theorems will be added to \HOL{}'s built-in database of useful facts as supplementary rewrite rules.
We will see that \ml{rw} is also somewhat knowledgeable about
arithmetic.\footnote{Linear arithmetic especially: purely universal
formulas involving the operators {\tt SUC}, $+$, $-$, numeric
literals, $<$, $\leq$, $>$, $\geq$, $=$, and multiplication by numeric
literals.}
Sometimes simplification with \ml{rw} proves the goal immediately.
Often however, we are left with a goal that requires some study before one
realizes what lemmas are needed to conclude the proof.
Once these lemmas have been proven, or located in ancestor theories,
\ml{metis\_tac}%
\footnote{The \ml{metis\_tac} tactic performs resolution-style first-order proof search.}
can be invoked with them, with the expectation that it will find the right instantiations needed to finish the proof.
Note that these two operations, simplification and resolution-style
automatic proof search, will not suffice to perform all the proofs in
this example; in particular, our development will also need case
analysis and induction.

\paragraph{Finding theorems}
This raises the following question: how does one find the right lemmas
and rewrite rules to use?
This is quite a problem, especially since the number of ancestor theories, and the theorems in them,  is large.
There are several possibilities
\begin{itemize}
\item The help system can be used to look up definitions and
theorems, as well as proof procedures; for example, an invocation of
{\small
\begin{verbatim}
   help "arithmeticTheory"
\end{verbatim}}
will display all the definitions and theorems that have been stored in
the theory of arithmetic. However, the complete name of the item being
searched for must be known before the help system is useful, so the following
two search facilities are often more useful.
\item  \verb+DB.match+ allows the use of patterns to locate the
sought-for theorem. Any stored theorem having an instance of the pattern
as a subterm will be returned.
\item \verb+DB.find+ will use fragments of names as keys with which to
lookup information.
\end{itemize}

\paragraph{Tactic composition}
Once a proof of a proposition has been found, it is customary, although
not necessary, to embark on a process of \emph{revision}, in which the
original sequence of tactics is composed into a single tactic. Sometimes
the resulting tactic is much shorter, and more aesthetically pleasing in
some sense. Some users spend a fair bit of time polishing these tactics,
although there doesn't seem much real benefit in doing so, since they
are \emph{ad hoc} proof recipes, one for each theorem. In the
following, we will show how this is done in a few cases.

\section{Divisibility}

We start by proving a number of theorems about the \verb+divides+
relation.  We will see that each of these initial theorems can be
proved with a single invocation of \ml{metis\_tac}. Both \ml{rw}
and \ml{metis\_tac} are quite powerful reasoners, and the choice of a
reasoner in a particular situation is a matter of experience.  The
major reason that \ml{metis\_tac} works so well is that \verb+divides+
is defined by means of an existential quantifier, and \ml{metis\_tac}
is quite good at automatically instantiating existentials in the
course of proof. For a simple example, consider proving $\forall x.\
x\; \mathtt{divides}\; 0$. A new proposition to be proved is entered
to the proof manager via ``\ml{g}'', which starts a fresh goalstack:

\begin{session}
\begin{alltt}
>> g `!x. x divides 0`;
\end{alltt}
\end{session}
The proof manager tells us that it has only one proof to manage, and
echoes the given goal.  Now we expand the definition of
\verb+divides+. Notice that $\alpha$-conversion takes place in order to
keep distinct the $x$ of the goal and the $x$ in the definition of
\ml{divides}:
\begin{session}
\begin{alltt}
>> e (rw[divides_def]);
\end{alltt}
\end{session}
It is of course quite easy to instantiate the existential quantifier by
hand.
\begin{session}
\begin{alltt}
>> e (qexists_tac `0`);
\end{alltt}
\end{session}
Then a simplification step finishes the proof.
\begin{session}
\begin{alltt}
>> e (rw[]);
\end{alltt}
\end{session}

What just happened here? The application of \ml{rw} to the goal decomposed it to an empty list of subgoals; in other words the goal was proved by \ml{rw}.
Once a goal has been proved, it is popped off the goalstack, prettyprinted to the output, and the theorem becomes available for use by the level of the stack. When all the sub-goals required by \textit{that} level are proven, the corresponding goal at that level can be proven too.  This `unwinding' process continues until the stack is empty, or until it hits a goal with more than one remaining unproved subgoal.
This process may be hard to visualize,\footnote{Perhaps since we have used a stack to implement what is notionally a tree!} but that doesn't matter, since the goalstack was expressly written to allow the user to ignore such details.

We can sequence tactics with the \ml{\gt\gt} operator (also known as \ml{THEN}).
If our three interactions above are joined together with \ml{\gt\gt} to form a single tactic, we can try the proof again from the beginning (using the \ml{restart} function) and this time it will take just one step:
\begin{session}
\begin{alltt}
>>_ restart();

>> e (rw[divides_def] >> qexists_tac `0` >> rw[]);
\end{alltt}
\end{session}
We have seen one way to prove the theorem.
However, as mentioned earlier, there is another: one can let \ml{metis\_tac} expand the definition of \ml{divides} and find the required instantiation for \verb+x'+ from the theorem \ml{MULT\_CLAUSES}.%
\footnote{You might
  like to try typing \ml{MULT\_CLAUSES} into the interactive loop
  to see exactly what it states.}
\begin{session}
\begin{alltt}
>>_ restart();

>> e (metis_tac [divides_def, MULT_CLAUSES]);
\end{alltt}
\end{session}
As it runs, \ml{metis\_tac} prints out some possibly interesting diagnostics.
In any case, having done our proof inside the goalstack package, we now want to have access to the theorem value that we have proved.
We use the \ml{top\_thm} function to do this, and then use \ml{drop} to dispose of the stack:
\begin{session}
\begin{alltt}
>> val DIVIDES_0 = top_thm();
>> drop();
\end{alltt}
\end{session}

We have used \ml{metis\_tac} in this way to prove the following collection of theorems about \ml{divides}.
As mentioned previously, the theorems supplied to \ml{metis\_tac} in the following proofs did not (usually) come from thin air: in most cases some exploratory work with the simplifier (\ml{rw}) was done to open up definitions and see what lemmas would be required by \ml{metis\_tac}.

##use euclid-extras.ML

\begin{description}
\label{euclid:extra-proofs}
\item [\small{({\it DIVIDES\_0\/})}]
\begin{tabular}[t]{l}
\verb+!x. x divides 0+ \\ \hline
 \verb+metis_tac [divides_def, MULT_CLAUSES]+
\end{tabular}

\item[\small{({\it DIVIDES\_ZERO\/})}]
\begin{tabular}[t]{l}
\verb+!x. 0 divides x = (x = 0)+ \\ \hline
 \verb+metis_tac [divides_def, MULT_CLAUSES]+
\end{tabular}

\item[\small{({\it DIVIDES\_ONE\/})}]
\begin{tabular}[t]{l}
\verb+!x. x divides 1 = (x = 1)+ \\ \hline
 \verb+metis_tac [divides_def, MULT_CLAUSES, MULT_EQ_1]+
\end{tabular}

\item[\small{({\it DIVIDES\_REFL\/})}]
\begin{tabular}[t]{l}
\verb+!x. x divides x+ \\ \hline
 \verb+metis_tac [divides_def, MULT_CLAUSES]+ \\
\end{tabular}

\item[\small{({\it DIVIDES\_TRANS\/})}]
\begin{tabular}[t]{l}
\verb+!a b c. a divides b /\ b divides c ==> a divides c+ \\ \hline
 \verb+metis_tac [divides_def, MULT_ASSOC]+ \\
\end{tabular}
\item[\small{({\it DIVIDES\_ADD\/})}]
\begin{tabular}[t]{l}
\verb|!d a b. d divides a /\ d divides b ==> d divides (a+b)| \\ \hline
 \verb|metis_tac [divides_def,LEFT_ADD_DISTRIB]|
\end{tabular}

\item[\small{({\it DIVIDES\_SUB\/})}]
\begin{tabular}[t]{l}
\verb+!d a b. d divides a /\ d divides b ==> d divides (a-b)+ \\ \hline
 \verb+metis_tac [divides_def, LEFT_SUB_DISTRIB]+ \\
\end{tabular}

\item[\small{({\it DIVIDES\_ADDL\/})}]
\begin{tabular}[t]{l}
\verb|!d a b. d divides a /\ d divides (a+b) ==> d divides b| \\ \hline
 \verb+metis_tac [ADD_SUB, ADD_SYM, DIVIDES_SUB]+ \\
\end{tabular}

\item[\small{({\it DIVIDES\_LMUL\/})}]
\begin{tabular}[t]{l}
\verb+!d a x. d divides a ==> d divides (x * a)+ \\ \hline
 \verb+metis_tac [divides_def, MULT_ASSOC, MULT_SYM]+ \\
\end{tabular}

\item[\small{({\it DIVIDES\_RMUL\/})}]
\begin{tabular}[t]{l}
\verb+!d a x. d divides a ==> d divides (a * x)+ \\ \hline
 \verb+metis_tac [MULT_SYM, DIVIDES_LMUL]+ \\
\end{tabular}

\end{description}

\noindent We'll assume that the above proofs have been performed, and
that the appropriate ML names have been given to all of the theorems.
Now we encounter a lemma about divisibility that doesn't succumb to just a
single invocation of \ml{metis\_tac}:
\begin{description}
\item [\small{({\it DIVIDES\_LE\/})}]
\begin{tabular}[t]{l}
\verb+!m n. m divides n ==> m <= n \/ (n = 0)+ \\ \hline
\verb+rw[divides_def] >> rw[]+ \\
\end{tabular}
\end{description}
Let's see how this is proved.
The easiest way to start is to simplify with the definition of \ml{divides}:
\begin{session}
\begin{alltt}
>>_ g `!m n. m divides n ==> m <= n \/ (n = 0)`;

>> e (rw[divides_def]);
\end{alltt}
\end{session}

This goal is a disappointing one to have the simplifier produce.
Both disjuncts look as if they should simplify further:
the first looks as if we should be able to divide through by \holtxt{m} on both sides of the inequality, and the second looks like something we could attack with the knowledge that one of two factors must be zero if a multiplication equals zero.

The relevant theorems justifying such steps have already been proved in \ml{arithmeticTheory}; something we can confirm with the generally useful \ml{DB.match} function


\begin{holboxed}
\begin{verbatim}
   DB.match : string list -> term
                -> ((string * string) * (thm * class)) list
\end{verbatim}
\end{holboxed}
This function takes a list of theory names, and a pattern, and looks in the list of theories for any theorem, definition, or axiom that has an instance of the pattern as a subterm.
If the list of theory names is empty, then all loaded theories are
included in the search.
Let's look in the theory of arithmetic for the subterm to be rewritten.

\begin{session}
\begin{alltt}
>> DB.match ["arithmetic"] ``m <= m * x``;
\end{alltt}
\end{session}

This is just the theorem we'd like to use.
Using \ml{DB.match} again, you should now try to find the theorem that will simplify the other disjunct.
Because both are so generally useful, \ml{rw} already has both rewrites in its internal database, and all we need to do is rewrite once more to get those rewrites applied:
\begin{session}
\begin{alltt}
>> e (rw[]);
##assert can top_thm()
\end{alltt}
\end{session}

That was gratifyingly easy!
The process of {\it finding\/} the proof has now finished, and all that remains is for the proof to be packaged up into the single tactic we saw above.
Rather than use \ml{top\_thm} and the goalstack, we can bypass it and use the \ml{Theorem} syntax to store the proved theorem for future use.
This syntax names the theorem, states the goal and provides the tactic that will prove that goal.
It then stores the theorem in the current theory under the given name.
\begin{session}
\begin{alltt}
>> Theorem DIVIDES_LE:
     !m n. m divides n ==> m <= n \/ (n = 0)
   Proof rw[divides_def] >> rw[]
   QED
\end{alltt}
\end{session}
(Note how the statement of the goal is not given with enclosing quotation symbols (the \ml{Theorem} and \ml{Proof} lines take on that role).
Also, all of the keywords in the \ml{Theorem}-syntax have to be present starting at column 0 of the input.)
Storing theorems in our script record of the session in this style
(rather than with the goalstack) results in a more concise script, and
also makes it easier to turn our script into a theory file, as we do
in section~\ref{sec:script-to-theory}.

\subsection{Divisibility and factorial}

The next lemma, {\small{\it DIVIDES\_FACT\/}}, says that every number
greater than $0$ and $\leq n$ divides the factorial of
$n$. Factorial is found at \verb+arithmeticTheory.FACT+ and has been
defined by primitive recursion:
\begin{description}
\item [\small{({\it FACT\/})}]
\begin{minipage}[t]{0.5\textwidth}
\begin{verbatim}
  (FACT 0 = 1) /\
  (!n. FACT (SUC n) = SUC n * FACT n)
\end{verbatim}
\end{minipage}
\end{description}
A polished proof of {\small{\it DIVIDES\_FACT\/}} is the
following\footnote{This and subsequent proofs use the theorems proved
  on page~\pageref{euclid:extra-proofs}, which were added to the \ML{} environment
  after being proved.}:
>>__ prove(``!m n. 0 < m /\ m <= n ==> m divides (FACT n)``,
    `!p m. 0 < m ==> m divides (FACT (m + p))`
      suffices_by metis_tac[LESS_EQ_EXISTS] >>
    Induct_on `p` >>
    rw[FACT,ADD_CLAUSES] >| [
      Cases_on `m`, ALL_TAC
    ] >> metis_tac [FACT, DECIDE ``!x. ~(x < x)``,
                    DIVIDES_RMUL, DIVIDES_LMUL, DIVIDES_REFL])
\begin{description}
\item [\small{({\it DIVIDES\_FACT\/})}]
\begin{tabular}[t]{l}
\verb+!m n. 0 < m /\ m <= n ==> m divides (FACT n)+ \\ \hline
\verb|`!p m. 0 < m ==> m divides (FACT (m + p))` |\\
\verb+    suffices_by metis_tac[LESS_EQ_EXISTS] >>+\\
\verb+Induct_on `p` >>+\\
\verb+rw[FACT,ADD_CLAUSES,DIVIDES_RMUL] >>+\\
\verb+Cases_on `m` >>+\\
\verb+fs[FACT,DIVIDES_LMUL,DIVIDES_REFL]+\\
\end{tabular}
\end{description}
We will examine this proof in detail, so we should first attempt to understand why the theorem is true.
What's the underlying intuition?
Suppose $0 < m \leq n$, and so $\mbox{\tt FACT}\ n = 1 * \cdots * m * \cdots * n$.
To show $m\ \mbox{\tt divides}\ (\mbox{\tt FACT}\ n)$ means exhibiting a $q$ such that $q * m = \mbox{\tt FACT}\ n$.
Thus $q = \mbox{\tt FACT}\ n \div m$.
If we were to take this approach to the proof, we would end up having to find and apply lemmas about $\div$.
This seems to take us a little out of our way; isn't there a proof
that doesn't use division?
Well yes, we can prove the theorem by induction on $n - m$: in the base case, we will have to prove $n\; \mbox{\tt divides}\ (\mbox{\tt FACT}\; n)$, which ought to be easy; in the inductive case, the inductive hypothesis seems like it should give us what we need.
This strategy for the inductive case is a bit vague, because we are trying to mentally picture a slightly complicated formula, but we can rely on the system to accurately calculate the cases of the induction for us.
If the inductive case turns out to be not what we expect, we will have to re-think our approach.
\begin{session}
\begin{alltt}
>> g `!m n. 0 < m /\ m <= n ==> m divides (FACT n)`;
\end{alltt}
\end{session}
Instead of directly inducting on $n-m$, we will induct on a witness
variable, obtained by use of the theorem \verb+LESS_EQ_EXISTS+.
\begin{session}
\begin{alltt}
>> LESS_EQ_EXISTS;
\end{alltt}
\end{session}
\noindent Now we want to induct on the $p$ that our theorem says exists.
This effectively requires us to prove a slight restatement of the theorem.
We might prove the restatement as a separate lemma, but it is probably just as easy to do this inline with the (infix) \ml{suffices\_by} tactic:
\begin{session}
\begin{alltt}
>> e (`!m p. 0 < m ==> m divides FACT(m + p)`
        suffices_by metis_tac[LESS_EQ_EXISTS]);
\end{alltt}
\end{session}
The tactic that we provide after the \ml{suffices\_by} checks that the first argument does indeed imply the original goal.
If that tactic succeeds (as it does here), we have a new goal to prove.
Now we can perform the induction:
\begin{session}
\begin{alltt}
>> e (Induct_on `p`);
\end{alltt}
\end{session}
\noindent We now have two sub-goals to prove: a base case and a step case.
The first goal the system expects us to prove is the lowest one printed (it's closest to the cursor), the base-case.
This can obviously be simplified:
\begin{session}
\begin{alltt}
>> e (rw[]);
\end{alltt}
\end{session}
\noindent Now we can do a case analysis on $m$: if it is $0$, we have a
trivial goal; if it is a successor, then we can use the definition of
\ml{FACT} and the theorems \ml{DIVIDES\_RMUL} and
\ml{DIVIDES\_REFL}.
\begin{session}
\begin{alltt}
>> e (Cases_on `m`);
\end{alltt}
\end{session}

Here the first sub-goal goal has an assumption that is false.
We can demonstrate this to the system by using the \ml{DECIDE} function to prove a simple fact about arithmetic (namely, that no number $x$ is less than itself), and then passing the resulting theorem to \ml{METIS\_TAC}, which can combine this with the contradictory assumption.


\begin{session}
\begin{alltt}
>> e (metis_tac [DECIDE ``!x. ~(x < x)``]);
\end{alltt}
\end{session}

Alternatively, we could trust that \HOL{}'s existing theories somewhere include the fact that less-then is irreflexive, find that theorem using \ml{DB.match} (using the pattern \holtxt{x~$<$~x}), and then quote that theorem-name to \ml{metis\_tac}.

Another alternative would be to apply the simplifier directly to the sub-goal's assumptions.
Certainly, the simplifier has already been primed with the irreflexivity of less-than, so this seems natural.
This can be done with the \ml{fs} tactic:
\begin{session}
\begin{alltt}
>>_ b();
>> e (fs[]);
\end{alltt}
\end{session}

Using the theorems identified above the remaining sub-goal can
be proved with the simplifier \ml{rw}.

\begin{session}
\begin{alltt}
>> e (rw [FACT, DIVIDES_LMUL, DIVIDES_REFL]);
\end{alltt}
\end{session}
Now we have finished the base case of the induction and can move to the
step case. An obvious thing to try is simplification with the
definitions of addition and factorial:
\begin{session}
\begin{alltt}
>> e (rw [FACT, ADD_CLAUSES]);
\end{alltt}
\end{session}
\noindent And now, by \ml{DIVIDES\_RMUL} and the inductive hypothesis, we are
done:
\begin{session}
\begin{alltt}
>> e (rw[DIVIDES_RMUL]);
##assert can top_thm()
\end{alltt}
\end{session}
We have finished the search for the proof, and now turn to the task of
making a single tactic out of the sequence of tactic invocations we have
just made. We assume that the sequence of invocations has been kept
track of in a file or a text editor buffer. We would thus have something
like the following:
\begin{hol}
\begin{alltt}
>>__ restart();
##eval e (`!m p. 0 < m ==> m divides FACT (m + p)`
            suffices_by metis_tac[LESS_EQ_EXISTS]);
       e (Induct_on `p`);
       (*1*)
       e (rw[]);
       e (Cases_on `m`);
       (*1.1*)
       e (fs[]);
       (*1.2*)
       e (rw[FACT, DIVIDES_LMUL, DIVIDES_REFL]);
       (*2*)
       e (rw[FACT, ADD_CLAUSES]);
       e (rw[DIVIDES_RMUL]);
##assert can top_thm ()
\end{alltt}
\end{hol}
\noindent

We have added a numbering scheme to keep track of the branches in the
proof. We can stitch the above together directly into the following compound
tactic:

\begin{hol}
\begin{alltt}
  ##eval[tac] `!m p.  0 < m ==> m divides FACT (m + p)`
                suffices_by metis_tac[LESS_EQ_EXISTS] >>
              Induct_on `p` >| [
                rw[] >> Cases_on `m` >| [
                  fs[],
                  rw[FACT, DIVIDES_LMUL, DIVIDES_REFL]
                ],
                rw[FACT, ADD_CLAUSES] >> rw[DIVIDES_RMUL]
              ]
>>__ restart(); e tac;
##assert can top_thm ()
\end{alltt}
\end{hol}

\noindent This can be tested to see that we have made no errors:

\begin{session}
\begin{alltt}
>>_ restart();
>> e (`!m p.  0 < m ==> m divides FACT (m + p)`
        suffices_by metis_tac[LESS_EQ_EXISTS] >>
      Induct_on `p` >| [
        rw[] >> Cases_on `m` >| [
          fs[],
          rw[FACT, DIVIDES_LMUL, DIVIDES_REFL]
        ],
        rw[FACT, ADD_CLAUSES] >> rw[DIVIDES_RMUL]
      ]);
##assert can top_thm ()
\end{alltt}
\end{session}

For many users, this would be the end of dealing with this proof: the
tactic can now be packaged into a \ml{Theorem} declaration, and that
would be the end of it.
However, another user might notice that this tactic could be shortened.

One obvious step would be to merge the two successive invocations of the simplifier in the step case:
\begin{hol}
\begin{alltt}
  ##eval[tac] `!m p.  0 < m ==> m divides FACT (m + p)`
                suffices_by metis_tac[LESS_EQ_EXISTS] >>
              Induct_on `p`  >| [
                Cases_on `m` >| [
                  fs[],
                  rw[FACT, DIVIDES_LMUL, DIVIDES_REFL]
                ],
                rw[FACT, ADD_CLAUSES, DIVIDES_RMUL]
              ]
>>__ restart(); e tac;
##assert can top_thm()
\end{alltt}
\end{hol}

Now we'll make the occasionally dangerous assumption that the simplifications of the step case won't interfere with what is happening in the base case, and move the step case's tactic to precede the first \ml{\gt|}, using \ml{\gt\gt}.
When the \ml{Induct} tactic generates two sub-goals, the step case's simplification will be applied to both of them:
\begin{session}
\begin{alltt}
>>_ restart();
>> e (`!m p.  0 < m ==> m divides FACT (m + p)`
         suffices_by metis_tac[LESS_EQ_EXISTS] >>
      Induct_on `p` >> rw[FACT, ADD_CLAUSES, DIVIDES_RMUL]);
\end{alltt}
\end{session}
The step case has been dealt with, and as we hoped the base case has not been changed at all.
This means that our tactic can become
\begin{hol}
\begin{alltt}
  ##eval[it] `!m p.  0 < m ==> m divides FACT (m + p)`
               suffices_by metis_tac[LESS_EQ_EXISTS] >>
             Induct_on `p` >>
             rw[FACT, ADD_CLAUSES,DIVIDES_RMUL] >>
             (* base case only remains *)
             Cases_on `m` >| [
               fs[],
               rw[FACT,DIVIDES_LMUL,DIVIDES_REFL]
             ]
>>__ val tac = it; restart(); e tac;
##assert can top_thm ()
\end{alltt}
\end{hol}
In the base case, we have two invocations of the simplifier under the case-split on \holtxt{m}.
In general, the two different simplifier invocations do slightly different things in addition to simplifying the conclusion of the goal:
\begin{itemize}
\item \ml{rw} strips apart the propositional structure of the goal, and eliminates equalities from the assumptions
\item \ml{fs} simplifies the assumptions as well as the conclusion
\end{itemize}
However, in this case the goal where we used \ml{rw} did not include any propositional structure to strip apart, and so we can be confident that using \ml{fs} in the same place would also work.
Thus, we can merge the two sub-cases of the base-case into a single invocation of \ml{fs}:
\begin{hol}
\begin{alltt}
  ##eval[tac] `!m p.  0 < m ==> m divides FACT (m + p)`
                suffices_by metis_tac[LESS_EQ_EXISTS] >>
              Induct_on `p` >>
              rw[FACT, ADD_CLAUSES,DIVIDES_RMUL] >>
              Cases_on `m` >>
              fs[FACT,DIVIDES_LMUL,DIVIDES_REFL]
>>__ restart(); e tac;
##assert can top_thm()
>>__ val DIVIDES_FACT = top_thm()
\end{alltt}
\end{hol}

We have now finished our exercise in tactic revision.
Certainly, it would be hard to foresee that this final tactic would prove the goal; the lemmas passed to our invocations of the simplifier, and the final structure of the tactic have been found by an incremental process of revision.

\subsection{Divisibility and factorial (again!)}

In the previous proof, we made an initial simplification step in order
to expose a variable upon which to induct. However, the proof is
really by induction on $n - m$. Can we express this directly? The
answer is a qualified yes: the induction can be naturally stated, but
it leads to somewhat less natural goals.
\begin{session}
\begin{alltt}
>>_ restart();
>> e (Induct_on `n - m`);
\end{alltt}
\end{session}
This is slighly hard to read, so we sequence a call to the simplifier to strip both arms of the proof.
As before, use of \ml{\gt\gt} ensures that the tactic gets applied in both branches of the induction.
(We might also use \ml{rpt~strip\_tac} if we \emph{didn't} want the simplification to happen.)
\begin{session}
\begin{alltt}
>>_ b();
>> e (Induct_on `n - m` >> rw[]);
\end{alltt}
\end{session}
Looking at the first goal, we can see (by the anti-symmetry of ${\le}$) that $m = n$.
We can prove this fact, using \ml{rw} and add it to the hypotheses by use of the infix operator ``\ml{by}'':
\begin{session}
\begin{alltt}
>> e (`m = n` by rw[]);
\end{alltt}
\end{session}

\noindent We can now use simplification again to propagate the newly derived equality throughout the goal.
\begin{session}
\begin{alltt}
>> e (rw[]);
\end{alltt}
\end{session}
    At this point in the previous proof we did a case analysis on $m$.
    However, we already have the hypothesis that $m$ is positive
    (along with two other now useless hypotheses). Thus we know that
    $m$ is the successor of some number $k$. We might wish to assert
    this fact with an invocation of ``\ml{by}'' as follows:
\[
    \mbox{\ml{`?k. m = SUC k` by <tactic>}}
\]
But what is the tactic?
If we try \ml{rw}, it will fail since the embedded arithmetic decision procedure doesn't handle existential statements very well.
What to do?

In fact, that earlier case analysis will again do the job: but now we hide it away so that it is only used to prove this sub-goal.
When we execute \ml{Cases\_on `m`}, we will get a case where \holtxt{m} has been substituted out for \holtxt{0}.
This case will be contradictory given that we already have an assumption \holtxt{0~$<$~m}, and we can again use \ml{fs}.
In the other case, there will be an assumption that \holtxt{m} is some successor value, and this will make it easy for the simplifier to prove the goal.

Thus:
\begin{session}
\begin{alltt}
>> e (`?k. m = SUC k` by (Cases_on `m` >> fs[]));
\end{alltt}
\end{session}

\noindent Now the tactic we used before can finish this off:
\begin{session}
\begin{alltt}
>> e (fs[FACT, DIVIDES_LMUL, DIVIDES_REFL]);
\end{alltt}
\end{session}
That takes care of the base case.
For the induction step, things look a bit more difficult than in the earlier proof.
However, we can make progress by realizing that the hypotheses imply that $0 < n$ and so we can transform $n$ into a successor, thus enabling the unfolding of \ml{FACT}, as in the previous proof:
\begin{session}
\begin{alltt}
>> e (`0 < n` by rw[] >> `?k. n = SUC k` by (Cases_on `n` >> fs[]));
\end{alltt}
\end{session}
\noindent The proof now finishes in much the same manner as the previous one:
\begin{session}
\begin{alltt}
>> e (rw [FACT, DIVIDES_RMUL]);
##assert can top_thm()
\end{alltt}
\end{session}
\noindent We leave the details of stitching the proof together to the interested reader.

\section{Primality}

Now we move on to establish some facts about the primality of the
first few numbers: $0$ and $1$ are not prime, but $2$ is. Also, all
primes are positive. These are all quite simple to prove.

\begin{description}

\item [\small{({\it NOT\_PRIME\_0\/})}]
\begin{tabular}[t]{l}
\verb+~prime 0+ \\ \hline
\verb+rw[prime_def,DIVIDES_0]+ \\
\end{tabular}
>>__ val NOT_PRIME_0 = prove(``~prime 0``, rw[prime_def, DIVIDES_0])

\item [\small{({\it NOT\_PRIME\_1\/})}]
\begin{tabular}[t]{l}
\verb+~prime 1+ \\ \hline
\verb+rw[prime_def]+ \\
\end{tabular}
>>__ val NOT_PRIME_1 = prove(``~prime 1``, rw[prime_def])

\item [\small{({\it PRIME\_2\/})}]
\begin{tabular}[t]{l}
\verb+prime 2+ \\ \hline
\verb+rw[prime_def] >>+ \\
\verb+metis_tac [DIVIDES_LE, DIVIDES_ZERO, DECIDE ``2<>0``,+ \\
\verb+           DECIDE ``x <= 2 <=> (x=0) \/ (x=1) \/ (x=2)``]+ \\
\end{tabular}
>>__ val PRIME_2 = prove(``prime 2``,
   rw[prime_def] >>
   metis_tac[DIVIDES_LE, DIVIDES_ZERO, DECIDE ``2<>0``,
             DECIDE ``x <= 2 <=> x=0 \/ x=1 \/ x=2``])

\item [\small{({\it PRIME\_POS\/})}]
\begin{tabular}[t]{l}
\verb+!p. prime p ==> 0<p+ \\ \hline
\verb+Cases >> rw[NOT_PRIME_0]+ \\
>>__ val PRIME_POS = prove(
       ``!p. prime p ==> 0 < p``, Cases >> rw[NOT_PRIME_0])
\end{tabular}
\end{description}

\section{Existence of prime factors}

Now we are in position to prove a more substantial lemma: every number
other than $1$ has a prime factor. The proof proceeds by a
\emph{complete induction} on $n$. Complete induction is
necessary since a prime factor won't be the predecessor. After
induction, the proof splits into cases on whether $n$ is prime or
not. The first case ($n$ is prime) is
trivial. In the second case, there must be an $x$ that divides $n$, and
$x$ is not $1$ or $n$. By {\small\it DIVIDES\_LE}, $n=0$ or $x \leq n$. If
$n=0$, then $2$ is a prime that divides $0$. On the other hand, if $x \leq
n$, there are two cases: if $x < n$ then we can use the inductive
hypothesis and by transitivity of divides we are done; otherwise,
$x=n$ and then we have a contradiction with the fact that $x$ is not 1
or $n$.  The polished tactic is the following:
\begin{description}
\item [\small{({\it PRIME\_FACTOR\/})}]
\begin{tabular}[t]{l}
\verb+!n. ~(n = 1) ==> ?p. prime p /\ p divides n+ \\ \hline
\verb+completeInduct_on `n` >>+ \\
\verb+  rw [] >>+ \\
\verb+  Cases_on `prime n` >| [+ \\
\verb+    metis_tac [DIVIDES_REFL], + \\
\verb+    `?x. x divides n /\ x<>1 /\ x<>n` + \\
\verb+      by METIS_TAC[prime_def] >>+ \\
\verb+    metis_tac [LESS_OR_EQ, PRIME_2, +\\
\verb+               DIVIDES_LE,DIVIDES_TRANS,DIVIDES_0]]+ \\
\end{tabular}
\end{description}
We start by invoking complete induction. This gives us an inductive
hypothesis that holds at every number $m$ strictly smaller than $n$:
\begin{session}
\begin{alltt}
>>__ proofManagerLib.dropn (case proofManagerLib.status() of
       Manager.PRFS l => List.length l)
>> g `!n. n <> 1 ==> ?p. prime p /\ p divides n`;

>> e (completeInduct_on `n`);
\end{alltt}
\end{session}
We can move the antecedent to the hypotheses and make our case
split. Notice that the term given to \ml{Cases\_on} need not occur in
the goal:
\begin{session}
\begin{alltt}
>> e (rw[] >> Cases_on `prime n`);
\end{alltt}
\end{session}
\noindent As mentioned, the first case is proved with the reflexivity of
divisibility:
\begin{session}
\begin{alltt}
>>_ e (metis_tac [DIVIDES_REFL]);
\end{alltt}
\end{session}
\noindent
In the second case, we can get a divisor of $n$ that isn't $1$ or $n$
(since $n$ is not prime):
\begin{session}
\begin{alltt}
>> e (`?x. x divides n /\ x<>1 /\ x<>n` by metis_tac [prime_def]);
\end{alltt}
\end{session}
At this point, the polished tactic simply invokes \ml{metis\_tac} with
a collection of theorems.
We will attempt a more detailed exposition.
Given the hypotheses, and by {\small\it DIVIDES\_LE}, we can assert $x < n \lor n = 0$ and thus split the proof into two cases:
\begin{session}
\begin{alltt}
>> e (`x < n \/ (n=0)` by metis_tac [DIVIDES_LE,LESS_OR_EQ]);
\end{alltt}
\end{session}
In the first subgoal, we can see that the antecedents of the inductive
hypothesis are met and so $x$ has a prime divisor. We can then use the
transitivity of divisibility to get the fact that this divisor of $x$ is
also a divisor of $n$, thus finishing this branch of the proof:
\begin{session}
\begin{alltt}
>> e (metis_tac [DIVIDES_TRANS]);
\end{alltt}
\end{session}
\noindent The remaining goal can be clarified by simplification:
\begin{session}
\begin{alltt}
>> e (rw[]);
\end{alltt}
\end{session}
We know that everything divides 0:
\begin{session}
\begin{alltt}
>> DIVIDES_0;
\end{alltt}
\end{session}
So any prime will do for \holtxt{p}.
\begin{session}
\begin{alltt}
>> e (metis_tac [PRIME_2, DIVIDES_0]);
>>__ val PRIME_FACTOR = top_thm();
\end{alltt}
\end{session}
Again, work now needs to be done to compose and perhaps polish a single tactic from the individual proof steps, but we will not describe it.%
\footnote{Indeed, the tactic can be simplified into complete induction followed by an invocation of \ml{METIS\_TAC} with suitable lemmas.}
Instead we move forward, because our ultimate goal is in reach.

\section{Euclid's theorem}

\noindent{\bf Theorem.} Every number has a prime greater than it.\\
\noindent  {\it Informal proof.} \\
\noindent Suppose the opposite; then there's an $n$
such that all $p$ greater than $n$ are not prime. Consider $\mbox{\tt
FACT}(n) + 1$: it's not equal to 1 so, by {\small{\it PRIME\_FACTOR}},
there's a prime $p$ that divides it. Note that $p$ also divides
$\mbox{\tt FACT}(n)$ because $p \leq n$. By {\small{\it DIVIDES\_ADDL}},
we have $p=1$. But then $p$ is not prime, which is a contradiction. \\
\noindent {\it End of proof}.

A HOL rendition of the proof may be given as follows:
\begin{description}
\item [\small{({\it EUCLID\/})}]
\begin{tabular}[t]{l}
\verb+!n. ?p. n < p /\ prime p+ \\ \hline
\verb+spose_not_then strip_assume_tac+ \\
\verb!  >> mp_tac (SPEC ``FACT n + 1`` PRIME_FACTOR)! \\
\verb+  >> rw[FACT_LESS, DECIDE ``~(x=0) = 0<x``]+ \\
\verb+  >> metis_tac [NOT_PRIME_1, NOT_LESS, PRIME_POS, + \\
\verb+                DIVIDES_FACT, DIVIDES_ADDL, DIVIDES_ONE]+ \\
\end{tabular}
\end{description}
Let's prise this apart and look at it in some detail. A proof by
contradiction can be started by using the \ml{bossLib} function
\ml{spose\_not\_then}. With it, one assumes the negation of the
current goal and then uses that in an attempt to prove falsity
(\verb+F+).
The assumed negation $\neg(\forall n.\ \exists p.\ n < p \land \mbox{\tt prime}\ p)$ is simplified a bit into $\exists n.\ \forall p.\ n < p \,\Rightarrow \, \neg \,\mbox{\tt prime}\ p$ and then is passed to the tactic \ml{strip\_assume\_tac}.
This moves its argument
to the assumption list of the goal after eliminating the existential
quantification on $n$.
\begin{session}
\begin{alltt}
>>_ g `!n. ?p. n < p /\ prime p`;

>> e (spose_not_then strip_assume_tac);
\end{alltt}
\end{session}
Thus we have the hypothesis that all $p$ beyond a certain unspecified
$n$ are not prime, and our task is to show that this cannot be. At this
point we take advantage of Euclid's great inspiration and we build an
explicit term from $n$. In the informal proof we are asked to `consider'
the term $\mbox{\tt FACT}\ n + 1$.\footnote{The HOL parser thinks
$\mbox{\tt FACT}\ n + 1$ is equivalent to $(\mbox{\tt FACT}\ n) + 1$.}
This term will have certain properties (\ie, it has a prime factor) that
lead to contradiction. Question: how do we `consider' this term in the
formal HOL proof? Answer: by instantiating a lemma with it and bringing the
lemma into the proof. The lemma and its instantiation are:\footnote{The
function {\tt SPEC} implements the rule of universal specialization.}
\begin{session}
\begin{alltt}
>> PRIME_FACTOR;

>> val th = SPEC ``FACT n + 1`` PRIME_FACTOR;
\end{alltt}
\end{session}
It is evident that the antecedent of \ml{th} can be eliminated. In
\holn{}, one could do this in a so-called {\it forward\/} proof style (by
proving $\vdash \neg(\mbox{\tt FACT}\ n + 1 = 1)$ and then applying {\it
modus ponens}, the result of which can then be used in the proof), or
one could bring \ml{th} into the proof and simplify it {\it in
situ}. We choose the latter approach.
\begin{session}
\begin{alltt}
>> e (mp_tac (SPEC ``FACT n + 1`` PRIME_FACTOR));
\end{alltt}
\end{session}
The invocation \ml{mp\_tac} ($\vdash M$) applied to a goal $(\Delta, g)$ returns the goal $(\Delta, M \Rightarrow g)$.
Now we simplify:
\begin{session}
\begin{alltt}
>> e (rw[]);
\end{alltt}
\end{session}
    We recall that zero is less than every factorial, a fact found in
    \ml{arithmeticTheory} under the name \ml{FACT\_LESS}. Thus we can
    solve the top goal by simplification:
\begin{session}
\begin{alltt}
>> e (rw[FACT_LESS, DECIDE ``!x. x<>0 <=> 0 < x``]);
\end{alltt}
\end{session}
Notice the `on-the-fly' use of \verb+DECIDE+ to provide an \textit{ad hoc}
rewrite. Looking at the remaining goal, one might think that our aim, to
prove falsity, has been lost. But this is not so: a goal
$\neg P \lor \neg Q$ is logically equivalent to $P \imp Q \imp \mathtt{F}$.
In the following invocation, we use the equality
$\vdash A \imp B = \neg A \lor B$ as a rewrite rule oriented right to left by
use of \ml{GSYM}.\footnote{Loosely speaking, \ml{GSYM} swaps the left and
right hand sides of any equations it finds.}
\begin{session}
\begin{alltt}
>> IMP_DISJ_THM;

>> e (rw[GSYM IMP_DISJ_THM]);
\end{alltt}
\end{session}

We can quickly proceed to show that $p \ \mathtt{divides}\ (\mathtt{FACT}\; n)$, so that if it also divides \holtxt{FACT n + 1}, then $p$ divides 1, meaning that $p = 1$.
But then $p$ is not prime, at which point we are done.
This can all be packaged into a single invocation of \ml{METIS\_TAC}:
\begin{session}
\begin{alltt}
>> e (metis_tac [DIVIDES_FACT, DIVIDES_ADDL, DIVIDES_ONE,
                 NOT_PRIME_1, NOT_LESS, PRIME_POS]);
\end{alltt}
\end{session}
    Euclid's theorem is now proved, and we can rest. However, this
    presentation of the final proof will be unsatisfactory to some,
    because the proof is completely hidden in the invocation of the
    automated reasoner. Well then, let's try another proof, this time
    employing the so-called `assertional' style. When used uniformly,
    this can allow a readable linear presentation that mirrors the
    informal proof. The following proves Euclid's theorem in the
    assertional style. We think it is fairly readable, certainly much
    more so than the standard tactic proof just given.\footnote{Note
      that {\tt CCONTR\_TAC}, which is used to start the proof,
      initiates a proof by contradiction by negating the goal and
      placing it on the hypotheses, leaving {\tt F} as the new goal.}

\begin{description}
\item [\small{({\it AGAIN\/})}]
\begin{tabular}[t]{l}
\verb+!n. ?p. n < p /\ prime p+ \\ \hline
\verb|CCONTR_TAC >> | \\
\verb|`?n. !p. n < p ==> ~prime p`  by metis_tac []             >>| \\
\verb|`~(FACT n + 1 = 1)`           by rw[FACT_LESS,| \\
\verb|                                    DECIDE``~(x=0)=0<x``] >>| \\
\verb|`?p. prime p /\  | \\
\verb|     p divides (FACT n + 1)`  by metis_tac [PRIME_FACTOR] >>| \\
\verb|`0 < p`                       by metis_tac [PRIME_POS]    >>| \\
\verb|`p <= n`                      by metis_tac [NOT_LESS]     >>| \\
\verb|`p divides FACT n`            by metis_tac [DIVIDES_FACT] >>| \\
\verb|`p divides 1`                 by metis_tac [DIVIDES_ADDL] >>| \\
\verb|`p = 1`                       by metis_tac [DIVIDES_ONE]  >>| \\
\verb|`~prime p`                    by metis_tac [NOT_PRIME_1]  >>| \\
\verb|metis_tac []| \\
\end{tabular}
\end{description}

\section{Turning the script into a theory}
\label{sec:script-to-theory}

Having proved our result, we probably want to package it up in a way
that makes it available to future sessions, but which doesn't require
us to go all through the theorem-proving effort again.  Even having a
complete script from which it would be possible to cut-and-paste is an
error-prone solution.

In order to do this we need to create a file with the name $x$\ml{Script.sml}, where $x$ is the name of the theory we wish to export.
This file then needs to be compiled.
In fact, we really do use the \ML{} compiler, carefully augmented with the appropriate logical context.
However, the language accepted by the compiler is not quite the same as that accepted by the interactive system, so we will need to do a little work to massage the original script into the correct form.

We'll give an illustration of converting to a form that can be
compiled using the script
\[
  \mbox{\ml{<holdir>/examples/euclid.sml}}
\] as our base-line.  This
file is already close to being in the right form.  It has all of the
proofs of the theorems in ``sewn-up'' form so that when run, it does
not involve the goal-stack at all.  In its given form, it can be run
as input to \textsf{hol} thus:

\setcounter{sessioncount}{0}
\begin{session}
\begin{verbatim}
$ cd examples/
$ ../bin/hol < euclid.sml
  ...

> val EUCLID = |- !n. ?p. n < p /\ prime p : thm
  ...

> val EUCLID_AGAIN = |- !n. ?p. n < p /\ prime p : thm
-
\end{verbatim}
\end{session}

However, we now want to create a \ml{euclidTheory} that we can load in
other interactive sessions.  So, our first step is to create a file
\ml{euclidScript.sml}, and to copy the body of \ml{euclid.sml} into
it.

The first non-comment line opens \ml{arithmeticTheory}.  However, when
writing for the compiler, we need to explicitly mention the other
\HOL{} modules that we depend on.  We must add
\[
\mbox{\ml{open HolKernel boolLib Parse bossLib}}
\]
The next line that poses a difficulty is
\[
  \mbox{\ml{set\_fixity "divides" (Infixr 450);}}
\]
While it is legitimate to type expressions directly into the
interactive system, the compiler requires that every top-level phrase
be a declaration.  We satisfy this requirement by altering this line
into a ``do nothing'' declaration that does not record the result of
the expression:
\[
\mbox{\ml{val \_{} = set\_fixity "divides" (Infixr 450)}}
\]
The only extra changes are to bracket the rest of the script text
with calls to \ml{new\_theory} and \ml{export\_theory}.  So,
before the definition of \ml{divides}, we add:
\[
\mbox{\ml{val \_{} = new\_theory "euclid";}}
\]
and at the end of the file:
\[
\mbox{\ml{val \_{} = export\_theory();}}
\]

Now, we can compile the script we have created using the
\textsf{Holmake} tool.  To keep things a little tidier, we first move
our script into a new directory.

\begin{session}
\begin{verbatim}
$ mkdir euclid
$ mv euclidScript.sml euclid
$ cd euclid
$ ../../bin/Holmake
Analysing euclidScript.sml
Trying to create directory .HOLMK for dependency files
Compiling euclidScript.sml
Linking euclidScript.uo to produce theory-builder executable
<<HOL message: Created theory "euclid".>>
Definition has been stored under "divides_def".
Definition has been stored under "prime_def".
Meson search level: .....
Meson search level: .................
 ...
Exporting theory "euclid" ... done.
Analysing euclidTheory.sml
Analysing euclidTheory.sig
Compiling euclidTheory.sig
Compiling euclidTheory.sml
\end{verbatim}
\end{session}

Now we have created four new files: various forms of \ml{euclidTheory}
with four different suffixes (three of which are hidden in the \texttt{.holobjs} directory).
Only \ml{euclidTheory.sig} is really suitable for human consumption, and this is put into the same directory as the \texttt{euclidScript.sml} file.
While still in the \ml{euclid} directory that we created, we can demonstrate:

\begin{session}
\begin{alltt}
\$ ../../bin/hol
[...]

[closing file "/local/scratch/mn200/Work/hol98/tools/end-init-boss.sml"]
- load "euclidTheory";
> val it = () : unit
- open euclidTheory;
> type thm = thm
  val DIVIDES_TRANS =
    |- !a b c. a divides b /\ b divides c ==> a divides c
    : thm
  ...
  val DIVIDES_REFL = |- !x. x divides x : thm
  val DIVIDES_0 = |- !x. x divides 0 : thm
\end{alltt}
\end{session}

\section{Summary}

The reader has now seen an interesting theorem proved, in great detail,
in \holn{}. The discussion illustrated the high-level tools provided in
\ml{bossLib} and touched on issues including tool selection, undo,
`tactic polishing', exploratory simplification, and the `forking-off' of
new proof attempts. We also attempted to give a flavour of the thought
processes a user would employ. Following is a more-or-less random
collection of other observations.
\begin{itemize}

\item Even though the proof of Euclid's theorem is short and easy to
understand when presented informally, a perhaps surprising amount of
support development was required to set the stage for Euclid's classic
argument.

\item The proof support offered by \ml{bossLib} (\ml{rw}, \ml{metis\_tac}, \ml{DECIDE}, \ml{Cases\_on}, \ml{Induct\_on}, and the ``\ml{by}'' construct) was nearly complete for this example: it was rarely necessary to resort to
lower-level tactics.

\item Simplification is a workhorse tactic; even when an automated
reasoner such as \ml{metis\_tac} is used, its application has often been
set up by some exploratory simplifications. It therefore pays to become
familiar with the strengths and weaknesses of the simplifier.

\item A common problem with interactive proof systems is dealing with
hypotheses. Often \ml{metis\_tac} and the ``\ml{by}'' construct allow
the use of hypotheses without directly resorting to indexing into them
(or naming them, which amounts to the same thing). This is desirable,
since the hypotheses are notionally a {\it set}, and moreover,
experience has shown that profligate indexing into hypotheses results in
hard-to-maintain proof scripts.

We also found that we could directly simplify in the assumptions by using the \ml{fs} tactic.
Nonetheless, it can be clumsy to work with a large set of hypotheses, in which case the following approaches may be useful.

One can directly refer to hypotheses by using \ml{UNDISCH\_TAC} (makes
the designated hypothesis the antecedent to the goal),
\ml{ASSUM\_LIST} (gives the entire hypothesis list to a tactic),
\ml{pop\_assum} (gives the top hypothesis to a tactic), and
\ml{qpat\_assum} (gives the first {\it matching\/} hypothesis to a
tactic). (See the \REFERENCE{} for further details on all of these.)
The numbers attached to hypotheses by the proof manager could likely
be used to access hypotheses (it would be quite simple to write such a
tactic). However, starting a new proof is sometimes the most
clarifying thing to do.

In some cases, it is useful to be able to delete a hypothesis. This can
be accomplished by passing the hypothesis to a tactic that ignores
it. For example, to discard the top hypothesis, one could invoke
\ml{pop\_assum~kall\_tac}.

\item In the example, we didn't use the more advanced features of
\ml{bossLib}, largely because they do not, as yet, provide much more
functionality than the simple sequencing of simplification, decision
procedures, and automated first order reasoning. The \ml{\gt\gt}
tactical has thus served as an adequate replacement. In the future,
these entrypoints should become more powerful.

\item It is almost always necessary to have an idea of the {\it
    informal\/} proof in order to be successful when doing a formal
  proof. However, all too often the following strategy is adopted by
  novices: (1) rewrite the goal with a few relevant definitions, and
  then (2) rely on the syntax of the resulting goal to guide
  subsequent tactic selection. Such an approach constitutes a clear
  case of the tail wagging the dog, and is a poor strategy to adopt.
  Insight into the high-level structure of the proof is one of the
  most important factors in successful verification exercises.

The author has noticed that many of the most successful verification
experts work using a sheet of paper to keep track of the main steps that
need to be made. Perhaps looking away to the paper helps break the
mesmerizing effect of the computer screen.

On the other hand, one of the advantages of having a mechanized logic
is that the machine can be used as a formal expression calculator,
and thus the user can use it to quickly and accurately explore various
proof possibilities.

\item High powered tools like \ml{metis\_tac},  and \ml{rw} are the principal way of advancing a proof in \ml{bossLib}.
In many cases, they do exactly what is desired, or even manage to surprise the user with their power.
In the formalization of Euclid's theorem, the tools performed fairly well. However, sometimes they are overly aggressive, or they simply flounder.
In such cases, more specialized proof tools need to be used, or even written, and hence the support underlying \ml{bossLib} must eventually be learned.

\item Having a good knowledge of the available lemmas, and where they
are located, is an essential part of being successful. Often powerful
tools can replace lemmas in a restricted domain, but in general, one has
to know what has already been proved. We have found that the entrypoints
in \verb+DB+ help in quickly finding lemmas.

\end{itemize}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "tutorial"
%%% End:
